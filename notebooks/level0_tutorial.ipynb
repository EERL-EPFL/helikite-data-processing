{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f90c902-0ec4-4bcc-b9c5-58940e4644ca",
   "metadata": {},
   "source": [
    "# Cleaner class example (LEVEL 0)\n",
    "\n",
    "The Cleaner class can be initialised and used to perform similar activities to the autoprocessing functionality.\n",
    "\n",
    "It relies on the definition of the instruments described in the [README.md](https://github.com/EERL-EPFL/helikite-data-processing?tab=readme-ov-file#the-instrument-class) to perform the instantiation.\n",
    "\n",
    "What happens in this first cell is we define where the input data resides, we instantiate the Cleaner class into a variable `cleaner`, which will scan for the files, load them into memory and allow us to work on all of the instruments in bulk.\n",
    "\n",
    "The functions used to clean the data and perform corrections are all specific to the `Instrument` and can be modified according to the definitions in the Instrument class. For an example, we can see the Flight Computer's instructions code in [the repository](https://github.com/EERL-EPFL/helikite-data-processing/blob/main/helikite/instruments/flight_computer.py). Editing this file and reloading the environment will alter its behaviour in this script.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46e045-6ccc-4a27-b5fb-05ab4a188427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helikite import Cleaner, instruments\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# The folder where the data resides. In this example, it is in the folder\n",
    "# 'rawdata' in relation to where we loaded jupyter lab from.\n",
    "INPUT_DATA = os.path.join(os.getcwd(), \"rawdata\")\n",
    "\n",
    "# Initialise the Cleaner class, scan the input data folder and import\n",
    "cleaner = Cleaner(\n",
    "    instruments=[\n",
    "        instruments.flight_computer_v1,  # These are the classes of the instruments\n",
    "        instruments.smart_tether,     # that contain all the functions to process\n",
    "        instruments.pops,             # each one. Add more or remove according to\n",
    "        instruments.msems_readings,   # the flight\n",
    "        instruments.msems_inverted,\n",
    "        instruments.msems_scan,\n",
    "        instruments.stap,\n",
    "    ],\n",
    "    reference_instrument=instruments.flight_computer_v1,  # We need a reference, in this flight it is the flight computer\n",
    "    input_folder=INPUT_DATA,\n",
    "    flight_date=datetime.date(2024,4,2),\n",
    "    # time_takeoff=datetime.datetime(2024,4,2,9,45,15),    # These are commented out as we can do this interactively below\n",
    "    # time_landing=datetime.datetime(2024,4,2,13,10),      # If you know them already, you can add them here as datetime objects\n",
    "    time_offset=datetime.time(0),                          # If there is a time_offset to apply, it can be defined here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536d951-858f-49d8-8184-936bb6a27f24",
   "metadata": {},
   "source": [
    "# Checking state\n",
    "\n",
    "Ok! Our class is now instantiated. The class looked at our input directory and guessed the files based on their `file_identifier()` method in their respective classes, as it happens if used from the CLI or Docker!\n",
    "\n",
    "There are no errors, so we can assume the raw CSVs have been loaded into memory according to how they are instructed to be read by the `read_data()` method in each instrument class. Each instrument can be accessed now with `cleaner.<instrument_name>` and it will have two pandas dataframes available as `.df` which will hold our data as we progress through any corrections, and a copy of it in `.df_raw` that will not be changed. \n",
    "\n",
    "These dataframes can both be used as you wish, as if you loaded them directly with pandas. If you want, you can stop here, and use them as if you imported them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75fccb-a0bb-4ba1-9408-577644de4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example\n",
    "cleaner.flight_computer.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672664a-71ea-4709-8fb9-837f942728d8",
   "metadata": {},
   "source": [
    "### Wait..\n",
    "But that's no fun, right? Let's try to make it a bit easier for ourselves! At least we know we are not bound by the capabilities of our library if we want to explore the data differently.\n",
    "\n",
    "The function .state() is now available to give a summary about how our class is managing our data. It can be used at any stage throughout the cleaning process to help us know what's happening inside of `cleaner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c952a4f-4977-4d3c-b7c4-13c933a92f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what it says now...\n",
    "cleaner.state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c1856-4291-4b2f-8703-65ec0ba98f15",
   "metadata": {},
   "source": [
    "### \"No operations have been completed\"\n",
    "\n",
    "What does that mean? Well, we can only perform some of these functions in a specific order, because they are mutating the data. We cannot perform them twice, and some require others to run before they can work on the next step. These are defined with a function decorator to define their dependencies in the `Cleaner` class, and the class tracks which ones have been executed. So as we progress we can see what we have done, if we execute a method that requires something prior, it will not work.\n",
    "\n",
    "So what can we do? Let's check what methods are available for us to continue with `.help()`\n",
    "\n",
    "Take note in each description, we can see what needs to be run first, and if that function can only execute once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120743b-32c8-4921-a245-c258fb0b6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588bb4ca-84e1-43e5-8022-cda812b29db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So if we try to run a function that has some dependencies, we will be told we cannot\n",
    "cleaner.correct_time_and_pressure(max_lag=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7e7a1-e235-4e90-a318-4a91c5a29cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try again, after performing the corrections\n",
    "cleaner.set_time_as_index()\n",
    "cleaner.data_corrections()\n",
    "cleaner.set_pressure_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b86c2-0e40-4070-a72f-856a27ff78e1",
   "metadata": {},
   "source": [
    "# Setting our flight times\n",
    "\n",
    "Now that the necessary functions have been executed to get the dataframes cleaned, we can try to set our flight times. We can do this interactively, by clicking on a time to start, then again on the end time (and if there's a mistake, to click on the first time again). All instruments are plotted, but we can only select the time from our reference instrument, which we set in the beginning as the `flight_computer`. We can zoom in to the plot to pick a good point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b70385-4099-49f5-a5f7-b3e80f878fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.define_flight_times()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53e9d3-b15c-4522-ae02-936898dfe63f",
   "metadata": {},
   "source": [
    "# Correct time and pressure based on time lag\n",
    "Let's correct the instruments based on their time lag to the reference instrument and plot the pressure to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3d7455-7e28-4d83-a745-fb8071d33766",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.correct_time_and_pressure(max_lag=180)\n",
    "cleaner.plot_pressure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7012b86-b7b6-4bcb-9b55-0aae13b98a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on preference, this could happen earlier\n",
    "cleaner.remove_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d96914-ac6b-44dc-a7d7-feea30419723",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36926b18-8227-4205-ad9d-405d9e48a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the instruments, they will become available in cleaner.master_df\n",
    "cleaner.merge_instruments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17349f0e-cfbc-476e-85cf-36cd328abd1c",
   "metadata": {},
   "source": [
    "# Check our merge\n",
    "\n",
    "As noted, we can look at the master dataframe in the `cleaner.master_df` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8452b-85e9-4995-81f5-44478e7128fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb369028-be39-4a86-b2fc-3f901c4816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner.export_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
