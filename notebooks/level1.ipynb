{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data processing - Level 1\n",
    "Code written by Radiance and Yolanda (with the help of ChatGPT)"
   ],
   "id": "b2a582f6a53b6b34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ],
   "id": "18615049a7ede4d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "FLIGHT_BASENAME = \"2025-02-12_A\"\n",
    "\n",
    "DATA_DIRPATH = Path(r\"C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\")\n",
    "\n",
    "DATA_FLIGHT_DIRPATH = DATA_DIRPATH / \"2024-2025_Sorted\" / FLIGHT_BASENAME\n",
    "DATA_PROCESSING_DIRPATH = DATA_DIRPATH / \"Processing\"\n",
    "\n",
    "DATA_LEVEL1_DIRPATH = DATA_PROCESSING_DIRPATH / \"Level1\"\n",
    "DATA_LEVEL0_DIRPATH = DATA_PROCESSING_DIRPATH / \"Level0\""
   ],
   "id": "bb43fa082e9a0b8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "b5677b688b904c24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.metadata.utils import load_parquet\n",
    "\n",
    "INPUT_DATA_FILE_BASENAME = 'level0_2025-02-12T07-55'\n",
    "\n",
    "INPUT_FILEPATH = DATA_LEVEL0_DIRPATH / f'{INPUT_DATA_FILE_BASENAME}.csv'\n",
    "\n",
    "OUTPUT_FILEPATH = DATA_LEVEL1_DIRPATH / f'level1_{FLIGHT_BASENAME}.csv'\n",
    "OUTLIER_FILEPATH = DATA_LEVEL1_DIRPATH / f'level1_{FLIGHT_BASENAME}_outliers.csv'\n",
    "\n",
    "df_level0, metadata = load_parquet(DATA_LEVEL0_DIRPATH / f\"{INPUT_DATA_FILE_BASENAME}.parquet\")"
   ],
   "id": "ced83562695d9b4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metadata",
   "id": "171e6ebf2d31bd27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Example commands to output different individual elements of the dataset**  \n",
    "\n",
    "*To use individual fields, just use the object (.) notation, for example*  \n",
    "  \n",
    "print(metadata.flight_date)  \n",
    "print(metadata.landing_time)  \n",
    "metadata.takeoff_time\n",
    "\n",
    "flight_computer_columns = [col for col in df.columns if col.startswith(\"flight_computer_\")]  \n",
    "print(flight_computer_columns)  \n",
    "\n",
    "smart_tether_columns = [col for col in df.columns if col.startswith(\"smart_tether_\")]  \n",
    "print(smart_tether_columns)"
   ],
   "id": "689484c4e41f30e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DataProcessor class",
   "id": "d7715f83cc6b68f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.classes.data_processing import DataProcessorLevel1, OutputSchemas\n",
    "\n",
    "data_processor = DataProcessorLevel1(df_level0, metadata, OutputSchemas.TURTMANN)\n",
    "data_processor.state()"
   ],
   "id": "d8a0d8cde4bad60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Outlier removal\n",
    "\n",
    "To remove outliers, load the level 0 CSV file, making sure to set the index to the DateTime.  \n",
    "This function will load all the data, plot an individual variable, and then save a CSV of any outliers that are chosen as True. This outlier CSV will be later used by ```data_processor.set_outliers_to_nan()``` to mask the values in the original dataframe.\n",
    "\n",
    "_Note: No data is changed in the input dataframe._\n",
    "  \n",
    "In a first time, check the **'flight_computer_pressure'** against **'flight_computer_time'** as well as **'flight_computer_Out1_T'**, **'flight_computer_Out2_T'**, **'flight_computer_Out1_H'** and **'flight_computer_Out2_H'**.  \n",
    "Then check **'smart_tether_Wind (m/s)'**. The WD values corresponding to the WS outliers will automatically also be set as outliers – no need to manually select **'smart_tether_Wind (degrees)'** outliers (if ```use_coupled_columns``` is ```True```).\n",
    "If needed, remove **'flight_computer_Lat'** outliers. The Long values corresponding to the Lat outliers will automatically also be set as outliers – no need to manually select **'flight_computer_Long'** outliers (if ```use_coupled_columns``` is ```True```).\n",
    "\n",
    "### Coupled columns\n",
    "To check which columns are coupled, see output of ```data_processor.state()```. To add new groups of coupled columns to an instrument, pass the list of all the groups to argument ```coupled_columns```  of the\n",
    "instrument instance. For example:\n",
    "```\n",
    "flight_computer_v1 = FlightComputerV1(\n",
    "    name=\"flight_computer\",\n",
    "    ...\n",
    "    coupled_columns=[\n",
    "        ('flight_computer_TEMP1', 'flight_computer_RH1'),\n",
    "        ('flight_computer_TEMP2', 'flight_computer_RH2'),\n",
    "    ]\n",
    ")\n",
    "```\n",
    " For the coupled columns to be updated, restart the kernel and rerun the cells."
   ],
   "id": "351e0e9b7de1ff9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.choose_outliers(y=\"flight_computer_pressure\", outlier_file=OUTLIER_FILEPATH, use_coupled_columns=True)\n",
    "# data_processor.choose_outliers(y=\"pops_pressure\", outlier_file=OUTLIER_FILEPATH)\n",
    "# data_processor.choose_outliers(y=\"cpc_DateTime\", outlier_file=OUTLIER_FILEPATH)"
   ],
   "id": "2980ae1d6219539a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If coupled columns were not specified when choosing outliers, ensure consistency manually.\n",
    "If coupled columns were specified, this adjustment is applied automatically."
   ],
   "id": "a68092abefb88143"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# outliers = pd.read_csv(OUTLIER_FILEPATH, index_col=0, parse_dates=True)\n",
    "# outliers[\"smart_tether_Wind (degrees)\"] = outliers[\"smart_tether_Wind (m/s)\"]   # Remove WD values corresponding to outlying WS\n",
    "# outliers[\"flight_computer_Long\"] = outliers[\"flight_computer_Lat\"]              # Remove Long values corresponding to outlying Lat\n",
    "# outliers.to_csv(OUTLIER_FILEPATH, date_format=\"%Y-%m-%d %H:%M:%S\")              # Save corresponding outliers into the csv file"
   ],
   "id": "e15c5caead50cfbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set GPS data in case of missing FC files\n",
    "data_processor.fillna_if_all_missing({\"flight_computer_Lat\": 7039.724, \"flight_computer_Long\": 817.1591})"
   ],
   "id": "ab1f965b48702df7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.state()",
   "id": "bfc87422e1c9cbed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# outliers = pd.read_csv(OUTLIER_FILENAME, index_col=0, parse_dates=True)\n",
    "# df.loc[outliers.index] = df.loc[outliers.index].mask(outliers)"
   ],
   "id": "9f2baaa441f16229",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.set_outliers_to_nan()\n",
    "#df.loc[\"2025-02-15 09:47:40\":\"2025-02-15 09:47:50\", 'smart_tether_Wind (m/s)']   # Print time range to control if values replaced by NaN"
   ],
   "id": "c1453be577e47ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "# df['flight_computer_pressure'] = df['pops_pressure']"
   ],
   "id": "b9f4404bb98219e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Outlier removal double check\n",
    "Plot variables with possible removed outliers."
   ],
   "id": "fa46c56342ea46e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_outliers_check()",
   "id": "a74a0ddc6cd552d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check position of balloon compared to the station based on GPS coordinates.  \n",
    "\n",
    "Transformation of degrees-minutes coordinates (DM) into decimal degrees (DD) coordinates.  \n",
    "Addition of 'latitude_dd' and 'longitude_dd' into df."
   ],
   "id": "36fe4bb1c69e926e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_gps_on_map()",
   "id": "6745f57743176c7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## T and RH averaging\n",
    "\n",
    "Averages flight computer temperature and humidity data from the two T/RH sensors (if >90 NaNs for one of the sensors, takes only the other one into account).  \n",
    "Plots T and RH in function of pressure.  \n",
    "Smart Tether is also plotted as indication, but not taken into account for the averaging. \n",
    "\n",
    "Adds 'Average_Temperature' and 'Average_RH' into df."
   ],
   "id": "91dfc1b1c7a33f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.T_RH_averaging()",
   "id": "1ec349a38cefcb2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**In case the standard T and RH averaging is not working or needs to be adapted :**",
   "id": "275e7a2111789194"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if False:\n",
    "    #df['smart_tether_T (deg C)_corr'] = df['smart_tether_T (deg C)'] - 0.2\n",
    "    #df['smart_tether_%RH_corr'] = df['smart_tether_%RH'] -6.1\n",
    "\n",
    "    #df['Average_Temperature'] = df[['flight_computer_Out1_T', 'flight_computer_Out2_T', 'smart_tether_T (deg C)_corr']].mean(axis=1, skipna=True)\n",
    "    #df['Average_RH'] = df[['flight_computer_Out1_H', 'flight_computer_Out2_H', 'smart_tether_%RH_corr']].mean(axis=1)\n",
    "\n",
    "    df['Average_Temperature'] = df['smart_tether_T (deg C)']\n",
    "    df['Average_RH'] = df['smart_tether_%RH']\n",
    "    df['Average_Temperature'] = df['Average_Temperature'].ffill().bfill()\n",
    "    df['Average_RH'] = df['Average_RH'].ffill().bfill()\n",
    "\n",
    "\n",
    "    # PLOT\n",
    "    plt.close('all')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "    # Temperature plot\n",
    "    #ax[0].plot(df[\"flight_computer_Out1_T\"], df[\"flight_computer_pressure\"], label=\"Out1_T\", color='blue')\n",
    "    #ax[0].plot(df[\"flight_computer_Out2_T\"], df[\"flight_computer_pressure\"], label=\"Out2_T\", color='orange')\n",
    "    ax[0].plot(df[\"Average_Temperature\"], df[\"flight_computer_pressure\"], label=\"Average_T\", color='red')\n",
    "    ax[0].plot(df[\"smart_tether_T (deg C)\"], df[\"flight_computer_pressure\"], label=\"ST_T\", color='green', linestyle='--')\n",
    "    ax[0].set_xlabel(\"Temperature (°C)\")\n",
    "    ax[0].set_ylabel(\"Pressure (hPa)\")\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "    ax[0].invert_yaxis()\n",
    "\n",
    "    # Humidity plot\n",
    "    #ax[1].plot(df[\"flight_computer_Out1_H\"], df[\"flight_computer_pressure\"], label=\"Out1_RH\", color='blue')\n",
    "    #ax[1].plot(df[\"flight_computer_Out2_H\"], df[\"flight_computer_pressure\"], label=\"Out2_RH\", color='orange')\n",
    "    ax[1].plot(df[\"Average_RH\"], df[\"flight_computer_pressure\"], label=\"Average_RH\", color='red')\n",
    "    ax[1].plot(df[\"smart_tether_%RH\"], df[\"flight_computer_pressure\"], label=\"ST_RH\", color='green', linestyle='--')\n",
    "    ax[1].set_xlabel(\"Relative Humidity (%)\")\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "27e56507698ce0e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.df",
   "id": "1485280ae0a4581a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Altitude calculation \n",
    "\n",
    "Adds 'DateTime', 'Pressure_ground', 'Temperature_ground' and 'Altitude' into df."
   ],
   "id": "7becdc4278423e0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "data_processor.altitude_calculation_barometric()\n",
    "data_processor.df.head()"
   ],
   "id": "22b31b7fdd922414",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**When start and/or stop of FC at balloon height and not on the sledge : add 3.5 m**",
   "id": "e85758fad5ad8f74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if False:\n",
    "    df['Altitude'] = df['Altitude'] + 3.5\n",
    "\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df.index, df['Altitude'], label='Altitude')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Altitude (m)')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "795bd6ca59e78c77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CO2 data processing",
   "id": "ef7afd96e7cddce4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.process_CO2_STP()",
   "id": "43dbc84f1aea3bff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## STAP data processing",
   "id": "740103797e3d9698"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.STAP_STP_normalization()",
   "id": "c57957fa7573e285",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## POPS data processing\n",
    "### POPS total concentration calculation\n",
    "\n",
    "Calculate the total concentration and dN/dlogDP for each bin\n",
    "\n",
    "From Pohorsky et al. (2024) it appeared that particles with diameters between 142 and 186 (bins 0 to 2) are wrongly detected by the POPS as total particle concentration increases. This phenomenon can be explained by electronic noise from the detector, where fringes on the edge of the Gaussian signal are perceived as smaller particles by the software. It was therefore decided to only consider data for particles larger than 186 nm as the error induced by the first three bins is too high.\n",
    "\n",
    "*dN_pops = pops_bX / popsflow_mean = dN*  \n",
    "*pops_total_conc = sum of dN_pops*  \n",
    "*pops_bX_dlogDp = dN/dlogDp*  \n",
    "\n",
    "Adds 'pops_total_conc' and 'pops_bX_dlogDp' into df."
   ],
   "id": "94c8e4ddc58f8274"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(df.columns.tolist())\n",
    "pops_data= [col for col in data_processor.df if col.startswith('pops_')]\n",
    "print(data_processor.df[pops_data].columns.tolist())"
   ],
   "id": "6e04a5e6d43cae05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no POPS measurements, add columns with NaN into dataset.**",
   "id": "9cd303eb1eda1c48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import pops\n",
    "# If no POPS\n",
    "new_pops_cols = pops.get_expected_columns(level=0, is_reference=metadata.reference_instrument == pops.name)\n",
    "\n",
    "# Add each column to df with NaN values\n",
    "if not pops_data:\n",
    "    for col in new_pops_cols:\n",
    "        data_processor.df[col] = np.nan"
   ],
   "id": "1119b177fde5e5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.POPS_total_conc_dNdlogDp()",
   "id": "ab5206445842daf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Apply in case of POPS outlier to replace by NaN at a specific timestamp**",
   "id": "296fbf07add64b84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    pops_b_cols = [col for col in df.columns if col.startswith('pops_b')]\n",
    "    cols_to_nan = pops_b_cols + ['pops_total_conc']\n",
    "\n",
    "    timestamp = pd.Timestamp(\"2025-02-12 07:57:25\")\n",
    "    df.loc[timestamp, cols_to_nan] = np.nan"
   ],
   "id": "f8f038299645d120",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Apply in case of intervals with POPS measurements = 0**  ",
   "id": "2d2421240b13630"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.dates as mdates\n",
    "from matplotlib.widgets import Button\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib widget\n",
    "plt.close('all')\n",
    "\n",
    "# Plot setup\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "palette = [\"#F54B0F\", \"#415067\"]\n",
    "\n",
    "ax.plot(data_processor.df.index, data_processor.df[\"pops_total_conc\"], color=palette[0], linewidth=2)\n",
    "ax.grid(True, ls=\"--\", alpha=0.5)\n",
    "ax.set_ylim(-5, 400)\n",
    "ax.set_ylabel(\"POPS_total_conc (/cm3)\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "# Interaction logic\n",
    "selected_points = []\n",
    "stable_periods = []\n",
    "span_artists = []\n",
    "\n",
    "def onclick(event):\n",
    "    if event.inaxes != ax:\n",
    "        return\n",
    "\n",
    "    # Skip if zoom or pan mode is active\n",
    "    if plt.get_current_fig_manager().toolbar.mode != '':\n",
    "        return\n",
    "        \n",
    "    click_time = mdates.num2date(event.xdata)\n",
    "    selected_points.append(click_time)\n",
    "\n",
    "    ax.plot(event.xdata, event.ydata, 'o', color=palette[1], markersize=8)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    if len(selected_points) == 2:\n",
    "        start, end = sorted(selected_points)\n",
    "        stable_periods.append((start, end))\n",
    "        span = ax.axvspan(start, end, color=palette[1], alpha=0.2)\n",
    "        span_artists.append(span)\n",
    "        selected_points.clear()\n",
    "        fig.canvas.draw()\n",
    "results_df = None\n",
    "\n",
    "def finish_selection(event):\n",
    "    global results_df\n",
    "\n",
    "    if stable_periods:\n",
    "        results_df = pd.DataFrame(stable_periods, columns=['Start_Time', 'End_Time'])\n",
    "        results_df['Duration'] = results_df['End_Time'] - results_df['Start_Time']\n",
    "        \n",
    "        # Optional formatting\n",
    "        results_df['Start_Time'] = results_df['Start_Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        results_df['End_Time'] = results_df['End_Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        print(\"\\nSelected Stable Periods:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "\n",
    "        # Copy to clipboard\n",
    "        results_df.to_clipboard(index=False)\n",
    "        print(\"\\nResults copied to clipboard!\")\n",
    "    else:\n",
    "        print(\"No stable periods selected\")\n",
    "\n",
    "# Add button\n",
    "ax_button = plt.axes([0.82, 0.01, 0.15, 0.05])\n",
    "btn = Button(ax_button, 'Finish Selection', color='lightgoldenrodyellow')\n",
    "btn.on_clicked(finish_selection)\n",
    "\n",
    "# Hook up click handler\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "plt.title(\"Click to select stable periods\")\n",
    "plt.show()\n",
    "\n",
    "print(results_df)"
   ],
   "id": "48aa0b7933688988",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_df",
   "id": "fafc12d7c2d4217b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    # Save or load pops mask csv\n",
    "    results_df.to_csv(DATA_LEVEL1_DIRPATH / f\"Level1_{metadata.flight_date}_Flight_{metadata.flight}_POPSmask.csv\", index=False)\n",
    "    # results_df = pd.read_csv(DATA_LEVEL1_DIRPATH / f\"Level1_{metadata.flight_date}_Flight_{metadata.flight}_POPSmask.csv\")\n",
    "\n",
    "    # Mask pops data in selected time interval\n",
    "    pops_cols = [f'pops_b{i}_dlogDp' for i in range(16)] + ['pops_total_conc']\n",
    "\n",
    "    for _, row in results_df.iterrows():\n",
    "        start = row['Start_Time']\n",
    "        end = row['End_Time']\n",
    "        mask = (df.index >= start) & (df.index <= end)\n",
    "        df.loc[mask, pops_cols] = np.nan\n",
    "\n",
    "    df.loc[\"2025-02-10 13:47:00\":\"2025-02-10 13:47:15\", 'pops_b3_dlogDp']"
   ],
   "id": "43a997598b6ccf7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of POPS concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "\n",
    "       \n",
    "Adds 'pops_total_conc_stp' and 'pops_bX_dlogDp_stp' into df."
   ],
   "id": "7ff3c54ffaf52ee9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.POPS_STP_normalization()",
   "id": "803c8404d6bd7aca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot POPS size distribution and total concentration  \n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "f995171632b5f9fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments.pops import plot_pops_distribution\n",
    "\n",
    "plot_pops_distribution(data_processor.df, time_start=None, time_end=None)"
   ],
   "id": "7d98ba029b17523c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mSEMS data processing\n",
    "### mSEMS total concentration calculation\n",
    "\n",
    "*msems_inverted_Bin_ConcX = dN/dlogDp*  \n",
    "*msems_inverted_dN_Bin_ConcX = conc * dlogDp*  \n",
    "*msems_inverted_dN_totalconc = sum of msems_inverted_dN_Bin_ConcX*  \n",
    "\n",
    "Adds 'msems_inverted_dN_Bin_ConcX' and 'msems_inverted_dN_totalconc' into df."
   ],
   "id": "7a95a6c662d0c5bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(df.columns.tolist())\n",
    "msems_data= [col for col in data_processor.df if col.startswith('msems_inverted_')]\n",
    "print(data_processor.df[msems_data].columns.tolist())"
   ],
   "id": "d6c3b98f346a50ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no mSEMS measurements, add columns with NaN into dataset.**",
   "id": "5d6e45d06dd7043d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import msems_inverted\n",
    "\n",
    "new_msems_columns = msems_inverted.get_expected_columns(level=0, is_reference=metadata.reference_instrument == msems_inverted.name)\n",
    "\n",
    "if not msems_data:\n",
    "    for col in new_msems_columns:\n",
    "        if col not in data_processor.df.columns:\n",
    "            data_processor.df[col] = np.nan"
   ],
   "id": "77d69513fc1fb360",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.mSEMS_total_conc_dN()",
   "id": "bc4a55f4f276be2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of mSEMS concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "Adds 'msems_inverted_Bin_ConcX_stp' and 'msems_inverted_dN_totalconc_stp' to df."
   ],
   "id": "4582af1fcc415bd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.mSEMS_STP_normalization()",
   "id": "3a80077d00d19804",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot mSEMS size distribution and total concentration\n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "a770dea354cf9465"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments.msems import plot_msems_distribution\n",
    "\n",
    "plot_msems_distribution(data_processor.df, time_start=None, time_end=None)"
   ],
   "id": "bba89c23b57e8d0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Replace no data or flooded mSEMS measurements by NaN**",
   "id": "ea68c77ee4de08b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "if False:\n",
    "    # Define time range of \"bad\" mSEMS measurements\n",
    "    start_time = \"2025-01-27 17:55\"\n",
    "    end_time = \"2025-01-27 19:45\"\n",
    "\n",
    "    inverted_cols = [\n",
    "        col for col in df.columns\n",
    "        if col.startswith(\"msems_inverted_\") and col != \"msems_inverted_DateTime\"\n",
    "    ]\n",
    "\n",
    "    time_mask = (df.index >= pd.to_datetime(start_time)) & (df.index <= pd.to_datetime(end_time))\n",
    "\n",
    "    affected_rows = set()\n",
    "\n",
    "    # Apply only within the time range\n",
    "    for col in inverted_cols:\n",
    "        col_mask = df[col].map(lambda x: isinstance(x, (int, float)) and not np.isnan(x))\n",
    "        full_mask = time_mask & col_mask\n",
    "        affected_rows.update(df.index[full_mask])\n",
    "        df.loc[full_mask, col] = np.nan\n",
    "\n",
    "    # Count affected rows\n",
    "    print(f\"{len(affected_rows)} rows had numeric value replaced by NaN in 'msems_inverted_...' columns within the time range.\")"
   ],
   "id": "ee8ca33d9da448e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mCDA data processing\n",
    "### mCDA bin concentrations, total concentration and normalization per bin width\n",
    "\n",
    "For bins 1 to 256 :  \n",
    "*mcda_dataB X = raw counts*  \n",
    "*mcda_dataB X_dN = counts / (flow rate * sampling interval) = concentration*  \n",
    "*mcda_dN_totalconc = sum of mcda_dataBX_dN*  \n",
    "*mcda_dataB X_dN_dlogDp = dN/dlogDp = mcda_dataBX_dN / dlogDp*\n",
    "\n",
    "Adds 'mcda_dataB X_dN', 'mcda_dN_totalconc' and 'mcda_dataB X_dN_dlogDp' into df."
   ],
   "id": "4773f5d86138bc51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify columns to drop\n",
    "#mcda_data = [col for col in df.columns if col.startswith('mcda_')]\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "#df = df.drop(columns=mcda_data)"
   ],
   "id": "d15bf2ef49f5b4f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(df.columns.tolist())\n",
    "mcda_data= [col for col in data_processor.df if col.startswith('mcda_')]\n",
    "print(data_processor.df[mcda_data].columns.tolist())"
   ],
   "id": "d0a85c5abab1190d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no mCDA measurements, add columns with NaN into dataset.**",
   "id": "b36d24e616a7bae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from helikite.instruments import mcda\n",
    "\n",
    "# Identify the position of the last column that starts with 'msems_'\n",
    "msems_cols = [col for col in data_processor.df.columns if col.startswith('msems_')]\n",
    "if not msems_cols:\n",
    "    raise ValueError(\"No columns starting with 'msems_' were found in the DataFrame.\")\n",
    "\n",
    "last_msems_index = data_processor.df.columns.get_loc(msems_cols[-1])\n",
    "\n",
    "# Define your new columns\n",
    "new_mcda_cols = mcda.get_expected_columns(level=0, is_reference=metadata.reference_instrument == mcda.name)\n",
    "\n",
    "if not mcda_data:\n",
    "    # Create a DataFrame with those new columns (filled with NaN)\n",
    "    mcda_df = pd.DataFrame(np.nan, index=data_processor.df.index, columns=new_mcda_cols)\n",
    "\n",
    "    # Insert the new columns into df at the correct position\n",
    "    df = pd.concat([data_processor.df.iloc[:, :last_msems_index+1], mcda_df, data_processor.df.iloc[:, last_msems_index+1:]], axis=1)"
   ],
   "id": "c70a66ebf64c606a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.mcda_concentration_calculations()",
   "id": "214167d9be3ec9e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of mCDA concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "Adds 'mcda_dataB X_dN_dlogDp_stp' and 'mcda_dN_totalconc_stp' to df."
   ],
   "id": "85f6ba6cf4dad069"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.mCDA_STP_normalization()",
   "id": "58d4fe4183c58fad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot mCDA size distribution and total concentration\n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "277445d9164a10b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments.mcda_instrument import Midpoint_diameter_list\n",
    "\n",
    "data_processor.plot_mcda_distribution(Midpoint_diameter_list)"
   ],
   "id": "fae277d0941e1d44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Vertical droplet size distribution**",
   "id": "ef49ee2271af231d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments.mcda_instrument import Midpoint_diameter_list\n",
    "\n",
    "data_processor.plot_mcda_vertical_distribution(Midpoint_diameter_list)"
   ],
   "id": "1646df5497f8e8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CPC3007 data processing",
   "id": "416a12cc44303407"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if 'cpc_totalconc_raw' in data_processor.df.columns:\n",
    "    print(data_processor.df['cpc_totalconc_raw'])"
   ],
   "id": "3b2f6bb80a337475",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no CPC measurements, add columns with NaN into dataset.**",
   "id": "def048998191365b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import cpc\n",
    "\n",
    "cpc.date = metadata.flight_date\n",
    "new_cpc_columns = cpc.get_expected_columns(level=0, is_reference=metadata.reference_instrument == cpc.name)\n",
    "\n",
    "for col in new_cpc_columns:\n",
    "    if col not in data_processor.df.columns:\n",
    "        data_processor.df[col] = np.nan"
   ],
   "id": "d5d83f046a8278a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of CPC3007 concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "\n",
    "       \n",
    "Adds 'CPC_total_N_stp' into df."
   ],
   "id": "42a1912e4c134f13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.CPC_STP_normalization()",
   "id": "679417c18dbef671",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.df[['cpc_totalconc_raw', 'cpc_totalconc_stp']].head()",
   "id": "30432b5e5643b8b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter data check",
   "id": "505e4de1ffab9807"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# NO FILT DATA FROM FC --> READ IN THE FILT FILE AND PASTE IT INTO DF WITH CORRECT NAMES !!!!!",
   "id": "83b75f66d898256a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    filt = pd.read_csv(DATA_FLIGHT_DIRPATH / \"250127A3.TXT\", skiprows=13, delimiter='\\t')  # or use sep=',' if it's CSV\n",
    "\n",
    "    date_str = filt['#YY/MM/DD'].str.strip()\n",
    "    time_str = filt['HR:MN:SC'].str.strip()\n",
    "    combined = date_str + ' ' + time_str\n",
    "    filt['datetime'] = pd.to_datetime(combined, format='%y/%m/%d %H:%M:%S')\n",
    "    filt = filt.set_index('datetime', drop=False)\n",
    "    filt.columns = 'flight_computer_F_' + filt.columns.astype(str)\n",
    "\n",
    "    filt"
   ],
   "id": "e12590dda4fce0d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    df = df.join(filt, how='left')\n",
    "    df"
   ],
   "id": "ada22e98cb21681a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.processing.post.level1 import filter_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close('all')\n",
    "%matplotlib ipympl\n",
    "\n",
    "if False:\n",
    "    filter_data(df)"
   ],
   "id": "d803ec3fd6b29b52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**In case of broken filters, replace filter positions by 1.**",
   "id": "bac036fdd3aed299"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    df['flight_computer_F_cur_pos'] = 1\n",
    "    df['flight_computer_F_pump_pw'] = 0"
   ],
   "id": "908b74a73a42b75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    df.loc[df['flight_computer_F_cur_pos'] == 0, 'flight_computer_F_cur_pos'] = 1\n",
    "    df.loc[df['flight_computer_F_cur_pos'] == 2, 'flight_computer_F_cur_pos'] = 1\n",
    "    df.loc[df['flight_computer_F_cur_pos'] == 4, 'flight_computer_F_cur_pos'] = 1"
   ],
   "id": "dff0e479f3199956",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    broken_filter_start = pd.Timestamp(\"2025-02-11 15:44:14\")\n",
    "    broken_filter_end = pd.Timestamp(\"2025-02-11 16:11:39\")\n",
    "    df.loc[df['flight_computer_F_cur_pos'] == 0, 'flight_computer_F_cur_pos'] = 1\n",
    "\n",
    "    df.loc[(df.index >= broken_filter_start) & (df.index <= broken_filter_end), 'flight_computer_F_cur_pos'] = 2.0\n",
    "    df.loc[(df.index >= broken_filter_start) & (df.index <= broken_filter_end), 'flight_computer_F_pump_pw'] = 37.0\n",
    "    df['flight_computer_F_cur_pos']"
   ],
   "id": "955057d191567d40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TAPIR data check",
   "id": "324acfe0f3b5c242"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tapir_data = [col for col in data_processor.df if col.startswith('tapir_')]\n",
    "print(data_processor.df[tapir_data].columns.tolist())"
   ],
   "id": "880f8fb6fe85aec9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no TAPIR measurements, add columns with NaN into dataset.**",
   "id": "46888ff44d8d54d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import tapir\n",
    "\n",
    "new_tapir_columns = tapir.get_expected_columns(level=0, is_reference=metadata.reference_instrument == tapir.name)\n",
    "\n",
    "if not tapir_data:\n",
    "    for col in new_tapir_columns:\n",
    "        data_processor.df[col] = np.nan\n",
    "\n",
    "data_processor.df[['tapir_GL', 'tapir_Lat', 'tapir_Le']].head()"
   ],
   "id": "1042b1daccc02bd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.df",
   "id": "b003782985373a2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data quicklooks",
   "id": "b97e6cb1e7f59be0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.processing.post.level1 import flight_profiles_1\n",
    "\n",
    "# Limits for x-axis (T, RH, mSEMS, CPC, POPS, mCDA, WS, WD)\n",
    "custom_xlim = {\n",
    "    'ax1': (-6, 2),\n",
    "    'ax2': (60, 100),\n",
    "    'ax3': (0, 1200), \n",
    "    'ax4': (0, 1200),\n",
    "    'ax5': (0, 60),\n",
    "    'ax6': (0, 60),\n",
    "    'ax7': (0, 12)\n",
    "}\n",
    "\n",
    "custom_xticks = {\n",
    "    'ax1': np.arange(-6, 3, 2),\n",
    "    'ax2': np.arange(60, 101, 10), \n",
    "    'ax3': np.arange(0, 1201, 200),\n",
    "    'ax4': np.arange(0, 1201, 200),\n",
    "    'ax5': np.arange(0, 61, 10),\n",
    "    'ax6': np.arange(0, 61, 10),\n",
    "    'ax7': np.arange(0, 13, 3)\n",
    "}\n",
    "\n",
    "# Plot title\n",
    "custom_title = f'Flight {metadata.flight} ({metadata.flight_date}_A) [Level 1]'\n",
    "\n",
    "fig = flight_profiles_1(data_processor.df, metadata, xlims=custom_xlim, xticks=custom_xticks, fig_title=custom_title)\n",
    "\n",
    "# Save the figure after plotting\n",
    "# filename = f'Level1_{metadata.flight_date}_A_Flight_{metadata.flight}.png'\n",
    "# save_path = DATA_LEVEL1_DIRPATH / filename\n",
    "# print(\"Saving figure to:\", save_path)\n",
    "# fig.savefig(save_path, dpi=300, bbox_inches='tight')"
   ],
   "id": "7b3223f694c199fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TEMPORAL PLOT OF FLIGHT with POPS and mSEMS HEAT MAPS\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "\n",
    "# Create figure with 3 subplots, sharing the same x-axis\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True, gridspec_kw={'height_ratios': [1, 1, 1, 1]})\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "\"\"\" SET THE TITLE OF THE PLOT (FLIGHT N° with DATE_X) \"\"\"\n",
    "# 'i' will automatically be replaced by the set flight number\n",
    "# '_X' has to be changed manually in function of the flight index of the day (A, B, ...)\n",
    "fig.suptitle(f'Flight {metadata.flight} ({metadata.flight_date}_A) [Level 1]', fontsize=16, fontweight='bold', y=0.91)\n",
    "\n",
    "### SUBPLOT 1: Altitude vs. Time\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df.index, df['Altitude'], color='black', linewidth=2, label='Altitude')\n",
    "\n",
    "ax1.set_ylabel('Altitude (m)', fontsize=12, fontweight='bold')\n",
    "ax1.tick_params(axis='y', labelsize=11)\n",
    "ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "ax1.tick_params(axis='x', labelbottom=False)\n",
    "ax1.set_ylim(-40, df['Altitude'].max() * 1.04)\n",
    "\n",
    "### SUBPLOT 2: mSEMS heatmmap & total concentration\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Get diameter bin averages\n",
    "start_dia = 'msems_inverted_Bin_Dia1'\n",
    "end_dia = 'msems_inverted_Bin_Dia60'\n",
    "bin_diameter_averages = df.loc[:, start_dia:end_dia].mean()\n",
    "\n",
    "# Get concentration data\n",
    "start_conc = 'msems_inverted_Bin_Conc1_stp'\n",
    "end_conc = 'msems_inverted_Bin_Conc60_stp'\n",
    "counts = df.loc[:, start_conc:end_conc]\n",
    "counts.index = df.index\n",
    "counts = counts.astype(float).dropna(how='any')\n",
    "counts = counts.clip(lower=1)\n",
    "\n",
    "# Create 2D grid\n",
    "xx, yy = np.meshgrid(counts.index.values, bin_diameter_averages)\n",
    "\n",
    "# Contour plot\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=1000)\n",
    "mesh = ax2.pcolormesh(xx, yy, counts.values.T, cmap='viridis', norm=norm, shading=\"gouraud\")\n",
    "\n",
    "# Colorbar\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = inset_axes(ax2, width=\"1.5%\", height=\"100%\", loc='lower left',\n",
    "                 bbox_to_anchor=(1.08, -0.025, 1, 1), bbox_transform=ax2.transAxes)\n",
    "cb = fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "cb.set_label('dN/dlogD$_p$ (cm$^{-3}$)', fontsize=13, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "\n",
    "# Add Secondary Y-axis for Total Concentration\n",
    "ax2_right = ax2.twinx()\n",
    "total_conc = df['msems_inverted_dN_totalconc_stp']\n",
    "ax2_right.scatter(df.index, total_conc, color='red', marker='.')\n",
    "ax2_right.set_ylabel('mSEMS conc (cm$^{-3}$)', fontsize=12, fontweight='bold', color='red', labelpad=8)\n",
    "ax2_right.tick_params(axis='y', labelsize=11, colors='red')\n",
    "#ax2_right.set_ylim(0, total_conc.max() * 1.1)\n",
    "\n",
    "# Labels and limits\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel('Part. Diameter (nm)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(8, 236)\n",
    "ax2.grid(True, linestyle='--', alpha=0.6, axis='x')\n",
    "\n",
    "\n",
    "### SUBPLOT 3: POPS heatmap & total concentration \n",
    "ax3 = axes[2]\n",
    "\n",
    "# Define pops_dlogDp variable from Hendix documentation\n",
    "pops_dia = [\n",
    "    149.0801282, 162.7094017, 178.3613191, 195.2873341, \n",
    "    212.890625, 234.121875, 272.2136986, 322.6106374, \n",
    "    422.0817873, 561.8906456, 748.8896681, 1054.138693,\n",
    "    1358.502538, 1802.347716, 2440.99162, 3061.590212\n",
    "]\n",
    "\n",
    "pops_dlogDp = [\n",
    "    0.036454582, 0.039402553, 0.040330922, 0.038498955,\n",
    "    0.036550107, 0.045593506, 0.082615487, 0.066315868,\n",
    "    0.15575785, 0.100807113, 0.142865049, 0.152476328,\n",
    "    0.077693935, 0.157186601, 0.113075192, 0.086705426\n",
    "]\n",
    "\n",
    "# Define the range of columns for POPS concentration\n",
    "start_conc = 'pops_b3_dlogDp_stp'\n",
    "end_conc = 'pops_b15_dlogDp_stp'\n",
    "\n",
    "# Get POPS concentration data\n",
    "pops_counts = df.loc[:, start_conc:end_conc]\n",
    "pops_counts = pops_counts.set_index(df.index).astype(float)\n",
    "\n",
    "# Create 2D grid\n",
    "#pops_dia = np.logspace(np.log10(180), np.log10(3370), num=pops_counts.shape[1])\n",
    "bin_diameters = pops_dia[3:16]\n",
    "xx, yy = np.meshgrid(pops_counts.index.values, bin_diameters)\n",
    "\n",
    "# Heatmap\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=300)\n",
    "mesh = ax3.pcolormesh(xx, yy, pops_counts.values.T, cmap='viridis', norm=norm, shading=\"gouraud\")\n",
    "\n",
    "# Colorbar\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = inset_axes(ax3, width=\"1.5%\", height=\"100%\", loc='lower left',\n",
    "                 bbox_to_anchor=(1.08, -0.025, 1, 1), bbox_transform=ax3.transAxes)\n",
    "cb = fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "cb.set_label('dN/dlogD$_p$ (cm$^{-3}$)', fontsize=12, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "\n",
    "# Labels and grid\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_ylabel('Part. Diameter (nm)', fontsize=12, fontweight='bold')\n",
    "ax3.tick_params(axis='y', labelsize=11)\n",
    "ax3.grid(True, linestyle='--', linewidth=0.5, axis='x')\n",
    "ax3.grid(False, axis='y')\n",
    "ax3.set_ylim(180, 3370)\n",
    "\n",
    "# Add Secondary Y-axis for Total POPS Concentration\n",
    "ax3_right = ax3.twinx()\n",
    "ax3_right.plot(df.index, df['pops_total_conc_stp'], color='red', linewidth=2, label='Total POPS Conc.')\n",
    "ax3_right.set_ylabel('POPS conc (cm$^{-3}$)', fontsize=12, fontweight='bold', color='red', labelpad=8)\n",
    "ax3_right.tick_params(axis='y', labelsize=11, colors='red')\n",
    "ax3_right.spines['right'].set_color('red')\n",
    "ax3_right.set_ylim(-20, df['pops_total_conc_stp'].max() * 1.1)\n",
    "\n",
    "### Subplot 4: mCDA heatmap & total concentration \n",
    "ax4 = axes[3]\n",
    "\n",
    "# Midpoint diameters \n",
    "Midpoint_diameter_list = np.array([\n",
    "    0.244381, 0.246646, 0.248908, 0.251144, 0.253398, 0.255593, 0.257846, 0.260141, 0.262561, 0.265062, 0.267712, 0.270370, 0.273159, 0.275904, 0.278724, 0.281554, 0.284585, 0.287661, 0.290892, 0.294127, 0.297512, 0.300813, 0.304101, 0.307439,\n",
    "    0.310919, 0.314493, 0.318336, 0.322265, 0.326283, 0.330307, 0.334409, 0.338478, 0.342743, 0.347102, 0.351648, 0.356225, 0.360972, 0.365856, 0.371028, 0.376344, 0.382058, 0.387995, 0.394223, 0.400632, 0.407341, 0.414345, 0.421740, 0.429371,\n",
    "    0.437556, 0.446036, 0.454738, 0.463515, 0.472572, 0.481728, 0.491201, 0.500739, 0.510645, 0.520720, 0.530938, 0.541128, 0.551563, 0.562058, 0.572951, 0.583736, 0.594907, 0.606101, 0.617542, 0.628738, 0.640375, 0.652197, 0.664789, 0.677657,\n",
    "    0.691517, 0.705944, 0.721263, 0.736906, 0.753552, 0.770735, 0.789397, 0.808690, 0.829510, 0.851216, 0.874296, 0.897757, 0.922457, 0.948074, 0.975372, 1.003264, 1.033206, 1.064365, 1.097090, 1.130405, 1.165455, 1.201346, 1.239589, 1.278023,\n",
    "    1.318937, 1.360743, 1.403723, 1.446000, 1.489565, 1.532676, 1.577436, 1.621533, 1.667088, 1.712520, 1.758571, 1.802912, 1.847836, 1.891948, 1.937088, 1.981087, 2.027604, 2.074306, 2.121821, 2.168489, 2.216644, 2.263724, 2.312591, 2.361099,\n",
    "    2.412220, 2.464198, 2.518098, 2.571786, 2.628213, 2.685162, 2.745035, 2.805450, 2.869842, 2.935997, 3.005175, 3.074905, 3.148598, 3.224051, 3.305016, 3.387588, 3.476382, 3.568195, 3.664863, 3.761628, 3.863183, 3.965651, 4.072830, 4.179050,\n",
    "    4.289743, 4.400463, 4.512449, 4.621025, 4.731530, 4.839920, 4.949855, 5.057777, 5.169742, 5.281416, 5.395039, 5.506828, 5.621488, 5.734391, 5.849553, 5.962881, 6.081516, 6.200801, 6.322133, 6.441786, 6.565130, 6.686935, 6.813017, 6.938981,\n",
    "    7.071558, 7.205968, 7.345185, 7.483423, 7.628105, 7.774385, 7.926945, 8.080500, 8.247832, 8.419585, 8.598929, 8.780634, 8.973158, 9.167022, 9.372760, 9.582145, 9.808045, 10.041607, 10.287848, 10.537226, 10.801172, 11.068405, 11.345135,\n",
    "    11.621413, 11.910639, 12.200227, 12.492929, 12.780176, 13.072476, 13.359067, 13.651163, 13.937329, 14.232032, 14.523919, 14.819204, 15.106612, 15.402110, 15.695489, 15.998035, 16.297519, 16.610927, 16.926800, 17.250511,\n",
    "    17.570901, 17.904338, 18.239874, 18.588605, 18.938763, 19.311505, 19.693678, 20.093464, 20.498208, 20.927653, 21.366609, 21.827923, 22.297936, 22.802929, 23.325426, 23.872344, 24.428708, 25.016547, 25.616663, 26.249815,\n",
    "    26.888493, 27.563838, 28.246317, 28.944507, 29.626186, 30.323440, 31.005915, 31.691752, 32.353900, 33.030123, 33.692286, 34.350532, 34.984611, 35.626553, 36.250913, 36.878655, 37.489663, 38.121550, 38.748073, 39.384594, \n",
    "    40.008540, 40.654627, 41.292757, 41.937789, 42.578436\n",
    "])\n",
    "\n",
    "# Prepare data\n",
    "counts = df.loc[:, 'mcda_dataB 1_dN_dlogDp_stp':'mcda_dataB 256_dN_dlogDp_stp']\n",
    "counts = counts.set_index(df.index)\n",
    "counts = counts.astype(float)\n",
    "counts[counts == 0] = np.nan\n",
    "\n",
    "bin_diameters = Midpoint_diameter_list\n",
    "xx, yy = np.meshgrid(counts.index.values, bin_diameters)\n",
    "Z = counts.values.T\n",
    "\n",
    "# Plot heatmap\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=50)\n",
    "mesh = ax4.pcolormesh(xx, yy, Z, cmap='viridis', norm=norm, shading=\"gouraud\")\n",
    "\n",
    "# Colorbar\n",
    "divider = make_axes_locatable(ax4)\n",
    "cax = inset_axes(ax4, width=\"1.5%\", height=\"100%\", loc='lower left',\n",
    "                 bbox_to_anchor=(1.08, -0.025, 1, 1), bbox_transform=ax4.transAxes)\n",
    "cb = fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "cb.set_label('dN/dlogD$_p$ (cm$^{-3}$)', fontsize=12, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "\n",
    "# Total concentration\n",
    "ax4_right = ax4.twinx()\n",
    "total_conc = df['mcda_dN_totalconc_stp']\n",
    "ax4_right.plot(df.index, total_conc, color='red', linewidth=2)\n",
    "ax4_right.set_ylabel('mCDA conc (cm$^{-3}$)', fontsize=12, fontweight='bold', color='red', labelpad=15)\n",
    "ax4_right.tick_params(axis='y', labelsize=11, colors='red')\n",
    "#ax4_right.set_ylim(0, total_conc.max() * 2)\n",
    "#ax4_right.set_xlim(ax4.get_xlim())\n",
    "\n",
    "# Axis styling\n",
    "ax4.set_yscale('log')\n",
    "ax4.set_ylabel('Part. Diameter (μm)', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylim(0.4, 20)\n",
    "ax4.grid(True, linestyle='--', linewidth=0.5, axis='x')\n",
    "ax4.grid(False, axis='y')\n",
    "\n",
    "# Legend for secondary y-axis\n",
    "#ax2_right.legend(['mSEMS total conc.'], loc='upper right', fontsize=11, frameon=False)\n",
    "#ax3_right.legend(['POPS total conc.'], loc='upper right', fontsize=11, frameon=False)\n",
    "#ax4_right.legend(['mCDA total conc.'], loc='upper right', fontsize=11, frameon=False)\n",
    "\n",
    "# X-axis formatting for all subplots\n",
    "ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax4.xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
    "ax4.set_xlabel('Time', fontsize=13, fontweight='bold', labelpad=10)\n",
    "ax4.tick_params(axis='x', rotation=90, labelsize=11)\n",
    "\n",
    "\n",
    "\"\"\" SET TIME RANGE (DATE + TIME) \"\"\"\n",
    "#ax3.set_xlim(pd.Timestamp('2025-02-12T07:55:00'), pd.Timestamp('2025-02-12T10:20:00'))\n",
    "\n",
    "\"\"\" SAVE PLOT \"\"\"\n",
    "# filename = f'Level1_{metadata.flight_date}_A_SizeDistr_Flight_{metadata.flight}.png'\n",
    "# save_path = DATA_LEVEL1_DIRPATH / filename\n",
    "# print(\"Saving figure to:\", save_path)\n",
    "# fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "15f115aec73606b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Level 1\n",
    "**Save file containing all the columns (processed)**"
   ],
   "id": "d3e175ee24d2a982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv(DATA_LEVEL1_DIRPATH / OUTPUT_FILEPATH, index=True)",
   "id": "36c45c5c859b38bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random code bits\n",
    "### Remove outliers from the Smart Tether WS and WD datapoints\n",
    "\n",
    "This is a **sliding-window median filter** used for **outlier detection and removal**.\n",
    "- Look at a window of neighboring values around each data point (10 neighboring values)\n",
    "- Compare the current point to the median of this window.\n",
    "- If the point is significantly different (>35% away from the median), it's treated as an outlier and **replaced with NaN**.\n",
    "\n",
    "Applied on WS, the corresponding WD datapoints are then also removed."
   ],
   "id": "d318a855fb26e367"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments.smart_tether import wind_outlier_removal\n",
    "%matplotlib ipympl\n",
    "\n",
    "df_filtered = wind_outlier_removal(df)"
   ],
   "id": "2f782e51885b4d91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**IF THE FILTER APPLIES CORRECTLY** : save the filtered WS and WD data back into th original dataframe",
   "id": "47315be3a0a42477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the filtered data back into th original dataframe\n",
    "df['smart_tether_Wind (m/s)'] = df_filtered['smart_tether_Wind (m/s)']\n",
    "df['smart_tether_Wind (degrees)'] = df_filtered['smart_tether_Wind (degrees)']\n",
    "print(\"Filtered data saved to the original dataframe.\")"
   ],
   "id": "5bfb890c8e71b6cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metadata dictionary",
   "id": "1d1971cd82358d58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Otherwise, to make a dictionary from the metadata:\n",
    "metadata_dict = metadata.model_dump()\n",
    "\n",
    "# Then use it as a normal Python dictionary\n",
    "metadata_dict['flight_date']"
   ],
   "id": "3dfa8b539d47d52c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The dataframe is unpacked into the 'df' variable from that function above\n",
    "df"
   ],
   "id": "1d737f883a2388ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GPS coordinate check",
   "id": "5873ee45b1297809"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# First y-axis for Longitude\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Longitude', color=color)\n",
    "ax1.plot(df.index, df['flight_computer_Long'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Second y-axis for Latitude\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Latitude', color=color)\n",
    "ax2.plot(df.index, df['flight_computer_Lat'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Longitude and Latitude over Time')\n",
    "plt.show()\n"
   ],
   "id": "bf624df4d50cfdc2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def convert_dm_to_dd(dm_value, direction):\n",
    "    if pd.isna(dm_value):\n",
    "        return None\n",
    "    degrees = int(dm_value / 100)\n",
    "    minutes = dm_value - degrees * 100\n",
    "    dd = degrees + minutes / 60\n",
    "    if direction in ['S', 'W']:\n",
    "        dd *= -1\n",
    "    return dd\n",
    "\n",
    "# Apply conversion to the entire column\n",
    "df['latitude_dd'] = df['flight_computer_Lat'].apply(lambda x: convert_dm_to_dd(x, 'S'))\n",
    "df['longitude_dd'] = df['flight_computer_Long'].apply(lambda x: convert_dm_to_dd(x, 'W'))\n",
    "df['latitude_dd']"
   ],
   "id": "5975b8371ac08bb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Export TAPIR data for Delphine ",
   "id": "152ceb4a57e6716d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['mcda_dN_totalconc_stp'] = np.nan",
   "id": "1d9e8fae1206fe1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a new DataFrame with the same DateTime index as df\n",
    "df_tapir = df.loc[:, ['Altitude', 'Average_Temperature', 'Temperature_ground', 'mcda_dN_totalconc_stp'] + \n",
    "                  [col for col in df.columns if col.startswith('tapir_')]]\n",
    "df_tapir['Altitude'] = df_tapir['Altitude'].round(2)\n",
    "df_tapir['Average_Temperature'] = df_tapir['Average_Temperature'].round(2)\n",
    "df_tapir['mcda_dN_totalconc_stp'] = df_tapir['mcda_dN_totalconc_stp'].round(2)\n",
    "\n",
    "df_tapir"
   ],
   "id": "809e68507fbdb31d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Example metadata as a dictionary (you can adjust this to your actual metadata object)\n",
    "metadata_lines = {\n",
    "    'Flight date' : metadata.flight_date,\n",
    "    'Flight number' : metadata.flight,\n",
    "    'Takeoff time' : metadata.takeoff_time,\n",
    "    'Landing time' : metadata.landing_time,\n",
    "    'Average_Temperature (in °C)' : 'average T from two temperature sensors',\n",
    "    'Temperature_ground (in K)' : 'extrapolated ground temperature based on T at takeoff and landing',\n",
    "    'mcda_dN_totalconc_stp (cm-3)' : 'droplet total concentration',\n",
    "    'Note' : 'there are two \"peaks\" in the temperature profile, I am however not yet sure if they are significant or outliers'\n",
    "}\n",
    "\n",
    "# Construct the dynamic filename\n",
    "filename = f\"{metadata.flight_date}_Flight{metadata.flight}_TAPIR.txt\"\n",
    "\n",
    "# Define your output directory (use raw string if needed)\n",
    "output_dir = 'tapir'\n",
    "\n",
    "# Combine the path and filename\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Save the file\n",
    "with open(output_path, 'w', newline='') as f:\n",
    "    for key, value in metadata_lines.items():\n",
    "        f.write(f\"# {key}: {value}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    df_tapir.to_csv(f, index=True)"
   ],
   "id": "af24abe6b08e344a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5c03af91882d58af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "caec8b353f86be8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6d4cf37be4463cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Export TAPIR data for Delphine ",
   "id": "3befd0fca96d3255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "955c9a10d8d9c066",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
