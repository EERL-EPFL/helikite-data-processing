{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data processing - Level 1\n",
    "Code written by Radiance and Yolanda (with the help of ChatGPT)"
   ],
   "id": "986263bd1a3cadfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "9cf165537707fd73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\" CHANGE BASE NAME OF INPUT FILE \"\"\"\n",
    "\n",
    "from helikite.metadata.utils import load_parquet\n",
    "\n",
    "INPUT_DATA_FILE_BASENAME = 'level0_2025-02-12T07-55'\n",
    "\n",
    "INPUT_DATA_FILENAME = f'{INPUT_DATA_FILE_BASENAME}.csv'\n",
    "OUTLIER_FILENAME = f'{INPUT_DATA_FILE_BASENAME}_outliers.csv'\n",
    "\n",
    "df, metadata = load_parquet(f\"{INPUT_DATA_FILE_BASENAME}.parquet\")"
   ],
   "id": "25f769b2b0f35070"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "metadata",
   "id": "3ab7e77d6721d5fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Example commands to output different individual elements of the dataset**  \n",
    "\n",
    "*To use individual fields, just use the object (.) notation, for example*  \n",
    "  \n",
    "print(metadata.flight_date)  \n",
    "print(metadata.landing_time)  \n",
    "metadata.takeoff_time\n",
    "\n",
    "flight_computer_columns = [col for col in df.columns if col.startswith(\"flight_computer_\")]  \n",
    "print(flight_computer_columns)  \n",
    "\n",
    "smart_tether_columns = [col for col in df.columns if col.startswith(\"smart_tether_\")]  \n",
    "print(smart_tether_columns)  "
   ],
   "id": "d0c463e405df9790"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Outlier removal\n",
    "\n",
    "To remove outliers, load the level 0 CSV file, making sure to set the index to the DateTime.  \n",
    "This function will load all the data, plot an individual variable, and then save a CSV of any outliers that are chosen as True. This outlier CSV can be used to mask the values in the original dataframe. An example of this is shown in the second cell.\n",
    "\n",
    "_Note: No data is changed in the input dataframe._  \n",
    "  \n",
    "In a first time, check the **'flight_computer_pressure'** against **'flight_computer_time'** as well as **'flight_computer_Out1_T'**, **'flight_computer_Out2_T'**, **'flight_computer_Out1_H'** and **'flight_computer_Out2_H'**.  \n",
    "Then check **'smart_tether_Wind (m/s)'**. The WD values corresponding to the WS outliers will automatically also be set as outliers (no need to manually select **'smart_tether_Wind (degrees)'** outliers).  \n",
    "If needed, remove **'flight_computer_Lat'** outliers by selecting a threshold value. The Long values corresponding to the Lat outliers will automatically also be set as outliers (no need to manually select **'flight_computer_Long'** outliers)."
   ],
   "id": "cd51c083cd4c56aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from helikite.processing import choose_outliers\n",
    "\n",
    "df = pd.read_csv(INPUT_DATA_FILENAME, low_memory=False, parse_dates=True, index_col=0)\n",
    "choose_outliers(df=df, y=\"flight_computer_pressure\", outlier_file=OUTLIER_FILENAME)\n",
    "#choose_outliers(df=df, y=\"pops_pressure\", outlier_file=OUTLIER_FILENAME)\n",
    "#choose_outliers(df=df, y=\"cpc_DateTime\", outlier_file=OUTLIER_FILENAME)"
   ],
   "id": "120013e830225b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "outliers = pd.read_csv(OUTLIER_FILENAME, index_col=0, parse_dates=True)\n",
    "outliers['smart_tether_Wind (degrees)'] = outliers['smart_tether_Wind (m/s)']   # Remove WS values corresponding to outlying WD"
   ],
   "id": "78f260d33a8373f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove WS = 0 and WS > 12 outliers\n",
    "wind_zero_mask = df['smart_tether_Wind (m/s)'] == 0\n",
    "wind_high_mask = df['smart_tether_Wind (m/s)'] > 10\n",
    "\n",
    "combined_wind_mask = wind_zero_mask | wind_high_mask\n",
    "\n",
    "selected_rows = pd.DataFrame(False, index=df[combined_wind_mask].index, columns=df.columns)\n",
    "selected_rows['smart_tether_Wind (m/s)'] = True\n",
    "selected_rows['smart_tether_Wind (degrees)'] = True  # Also flag the direction as outlier\n",
    "\n",
    "if 'outliers' not in locals():\n",
    "    outliers = selected_rows.copy()\n",
    "else:\n",
    "    outliers = pd.concat([outliers, selected_rows])"
   ],
   "id": "3ae79362c6037a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove GPS outliers\n",
    "lat_mask = (df['flight_computer_Lat'] <= 7039) | (df['flight_computer_Lat'] > 7100)\n",
    "long_mask = df['flight_computer_Long'] < 800\n",
    "\n",
    "combined_mask = lat_mask | long_mask  # Combine both masks using logical OR\n",
    "selected_rows = pd.DataFrame(False, index=df[combined_mask].index, columns=df.columns)\n",
    "selected_rows['flight_computer_Lat'] = True\n",
    "selected_rows['flight_computer_Long'] = True  # Mark both as outliers if either condition is true\n",
    "\n",
    "if 'outliers' not in locals():\n",
    "    outliers = selected_rows.copy()\n",
    "else:\n",
    "    outliers = pd.concat([outliers, selected_rows])"
   ],
   "id": "8c2e5fc002767fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set GPS data for missing FC files\n",
    "df['flight_computer_Lat'] = 7039.724\n",
    "df['flight_computer_Long'] = 817.1591"
   ],
   "id": "e0692e3f853e17e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove T and RH outliers\n",
    "start_time = pd.to_datetime(\"2025-02-08 19:55:39\")\n",
    "end_time = pd.to_datetime(\"2025-02-08 19:57:45\")\n",
    "time_mask = (df.index >= start_time) & (df.index <= end_time)\n",
    "\n",
    "temp_mask = pd.DataFrame(False, index=df[time_mask].index, columns=df.columns)\n",
    "temp_mask['flight_computer_Out1_T'] = True\n",
    "temp_mask['flight_computer_Out1_H'] = True\n",
    "\n",
    "if 'outliers' not in locals():\n",
    "    outliers = temp_mask.copy()\n",
    "else:\n",
    "    outliers = pd.concat([outliers, temp_mask])"
   ],
   "id": "3d51dbd7f4075bda"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove FC outliers\n",
    "intervals = [\n",
    "    (\"2025-02-11 15:48:23\", \"2025-02-11 16:10:01\"),\n",
    "    (\"2025-02-11 16:27:01\", \"2025-02-11 16:54:43\"),\n",
    "    (\"2025-02-11 16:58:37\", \"2025-02-11 17:08:12\"),\n",
    "]\n",
    "\n",
    "fc_cols = [col for col in df.columns if col.startswith('flight_computer_') and col != 'flight_computer_Time']\n",
    "FC_mask = pd.DataFrame(False, index=df.index, columns=df.columns)\n",
    "\n",
    "for start_str, end_str in intervals:\n",
    "    start, end = pd.Timestamp(start_str), pd.Timestamp(end_str)\n",
    "    mask = (df.index >= start) & (df.index <= end)\n",
    "    FC_mask.loc[mask, fc_cols] = True\n",
    "FC_mask = FC_mask.loc[FC_mask[fc_cols].any(axis=1)]\n",
    "\n",
    "if 'outliers' not in locals():\n",
    "    outliers = FC_mask.copy()\n",
    "else:\n",
    "    outliers = pd.concat([outliers, FC_mask])"
   ],
   "id": "d9b6baaf8db3ec81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Remove FC outliers\n",
    "timestamp = pd.Timestamp(\"2025-02-10 12:16:55\")\n",
    "fc_cols = [col for col in df.columns if col.startswith('flight_computer_')]\n",
    "FC_mask = pd.DataFrame(False, index=[timestamp], columns=df.columns)\n",
    "FC_mask.loc[timestamp, fc_cols] = True\n",
    "\n",
    "if 'outliers' not in locals():\n",
    "    outliers = FC_mask.copy()\n",
    "else:\n",
    "    outliers = pd.concat([outliers, FC_mask])"
   ],
   "id": "52836e9b5b993610"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "outliers = pd.read_csv(OUTLIER_FILENAME, index_col=0, parse_dates=True)\n",
    "#outliers['smart_tether_Wind (degrees)'] = outliers['smart_tether_Wind (m/s)']   # Remove WD values corresponding to outlying WS\n",
    "#outliers['flight_computer_Long'] = outliers['flight_computer_Lat']              # Remove Long values corresponding to outlying Lat\n",
    "#outliers.to_csv(OUTLIER_FILENAME, date_format=\"%Y-%m-%d %H:%M:%S\")              # Save corresponding outliers into the csv file\n",
    "\n",
    "num_WS = outliers['smart_tether_Wind (m/s)'].sum()\n",
    "print(f\"Number of outliers in 'smart_tether_Wind (m/s)': {num_WS}\")\n",
    "num_T1 = outliers['flight_computer_Out1_T'].sum()\n",
    "print(f\"Number of outliers in 'flight_computer_Out1_T': {num_T1}\")\n",
    "num_T2 = outliers['flight_computer_Out2_T'].sum()\n",
    "print(f\"Number of outliers in 'flight_computer_Out2_T': {num_T2}\")\n",
    "num_lat = outliers['flight_computer_Lat'].sum()\n",
    "print(f\"Number of outliers in 'flight_computer_Lat': {num_lat}\")"
   ],
   "id": "8da0ca4adc5da639"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set the values in the df to be np.nan (this is default behavior of a mask)\n",
    "df.loc[outliers.index] = df.loc[outliers.index].mask(outliers)                # By default the outliers will be nan\n",
    "\n",
    "#df.loc[\"2025-02-15 09:47:40\":\"2025-02-15 09:47:50\", 'smart_tether_Wind (m/s)']   # Print time range to control if values replaced by NaN"
   ],
   "id": "259f05a4541247b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#df['flight_computer_pressure'] = df['pops_pressure']",
   "id": "6a2e8f79d5111982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Outlier removal double check\n",
    "Plot variables with possible removed outliers."
   ],
   "id": "88ba07d8e72dfe65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.processing.post.outliers import plot_outliers_check\n",
    "%matplotlib ipympl\n",
    "\n",
    "plot_outliers_check(df)"
   ],
   "id": "65f7e948c57f86cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check position of balloon compared to the station based on GPS coordinates.  \n",
    "\n",
    "Transformation of degrees-minutes coordinates (DM) into decimal degrees (DD) coordinates.  \n",
    "Addition of 'latitude_dd' and 'longitude_dd' into df."
   ],
   "id": "169d5f2dd649567e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.processing.post.outliers import plot_gps_on_map\n",
    "\n",
    "m = plot_gps_on_map(df)\n",
    "m"
   ],
   "id": "1620c51fd7f4d603"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## T and RH averaging\n",
    "\n",
    "Averages flight computer temperature and humidity data from the two T/RH sensors (if >90 NaNs for one of the sensors, takes only the other one into account).  \n",
    "Plots T and RH in function of pressure.  \n",
    "Smart Tether is also plotted as indication, but not taken into account for the averaging. \n",
    "\n",
    "Adds 'Average_Temperature' and 'Average_RH' into df."
   ],
   "id": "752a5b3a63d50db0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.processing.post.TandRH import T_RH_averaging\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = T_RH_averaging(df)"
   ],
   "id": "aace7a8c93034878"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**In case the standard T and RH averaging is not working or needs to be adapted :**",
   "id": "b488c9a0384f1e2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#df['smart_tether_T (deg C)_corr'] = df['smart_tether_T (deg C)'] - 0.2\n",
    "#df['smart_tether_%RH_corr'] = df['smart_tether_%RH'] -6.1\n",
    "\n",
    "#df['Average_Temperature'] = df[['flight_computer_Out1_T', 'flight_computer_Out2_T', 'smart_tether_T (deg C)_corr']].mean(axis=1, skipna=True)\n",
    "#df['Average_RH'] = df[['flight_computer_Out1_H', 'flight_computer_Out2_H', 'smart_tether_%RH_corr']].mean(axis=1)\n",
    "\n",
    "df['Average_Temperature'] = df['smart_tether_T (deg C)']\n",
    "df['Average_RH'] = df['smart_tether_%RH']\n",
    "df['Average_Temperature'] = df['Average_Temperature'].ffill().bfill()\n",
    "df['Average_RH'] = df['Average_RH'].ffill().bfill()\n",
    "\n",
    "\n",
    "# PLOT\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Temperature plot\n",
    "#ax[0].plot(df[\"flight_computer_Out1_T\"], df[\"flight_computer_pressure\"], label=\"Out1_T\", color='blue')\n",
    "#ax[0].plot(df[\"flight_computer_Out2_T\"], df[\"flight_computer_pressure\"], label=\"Out2_T\", color='orange')\n",
    "ax[0].plot(df[\"Average_Temperature\"], df[\"flight_computer_pressure\"], label=\"Average_T\", color='red')\n",
    "ax[0].plot(df[\"smart_tether_T (deg C)\"], df[\"flight_computer_pressure\"], label=\"ST_T\", color='green', linestyle='--')\n",
    "ax[0].set_xlabel(\"Temperature (°C)\")\n",
    "ax[0].set_ylabel(\"Pressure (hPa)\")\n",
    "ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "ax[0].invert_yaxis()\n",
    "\n",
    "# Humidity plot\n",
    "#ax[1].plot(df[\"flight_computer_Out1_H\"], df[\"flight_computer_pressure\"], label=\"Out1_RH\", color='blue')\n",
    "#ax[1].plot(df[\"flight_computer_Out2_H\"], df[\"flight_computer_pressure\"], label=\"Out2_RH\", color='orange')\n",
    "ax[1].plot(df[\"Average_RH\"], df[\"flight_computer_pressure\"], label=\"Average_RH\", color='red')\n",
    "ax[1].plot(df[\"smart_tether_%RH\"], df[\"flight_computer_pressure\"], label=\"ST_RH\", color='green', linestyle='--')\n",
    "ax[1].set_xlabel(\"Relative Humidity (%)\")\n",
    "ax[1].legend()\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "590ea54d429b8ae4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df",
   "id": "c03669ae11394a21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Altitude calculation \n",
    "\n",
    "Adds 'DateTime', 'Pressure_ground', 'Temperature_ground' and 'Altitude' into df."
   ],
   "id": "6c849f36046bb93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.processing.post.altitude import altitude_calculation_barometric\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = altitude_calculation_barometric(df, metadata)\n",
    "df.head()"
   ],
   "id": "e2b3a22c5569cee4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**When start and/or stop of FC at balloon height and not on the sledge : add 3.5 m**",
   "id": "d532f851f6dc27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['Altitude'] = df['Altitude'] + 3.5\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, df['Altitude'], label='Altitude')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Altitude (m)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e2041c682575e229"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b1ab0dfa57dc2b8b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## POPS data processing\n",
    "### POPS total concentration calculation\n",
    "\n",
    "Calculate the total concentration and dN/dlogDP for each bin\n",
    "\n",
    "From Pohorsky et al. (2024) it appeared that particles with diameters between 142 and 186 (bins 0 to 2) are wrongly detected by the POPS as total particle concentration increases. This phenomenon can be explained by electronic noise from the detector, where fringes on the edge of the Gaussian signal are perceived as smaller particles by the software. It was therefore decided to only consider data for particles larger than 186 nm as the error induced by the first three bins is too high.\n",
    "\n",
    "*dN_pops = pops_bX / popsflow_mean = dN*  \n",
    "*pops_total_conc = sum of dN_pops*  \n",
    "*pops_bX_dlogDp = dN/dlogDp*  \n",
    "\n",
    "Adds 'pops_total_conc' and 'pops_bX_dlogDp' into df."
   ],
   "id": "6fe94b4928f6e94e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Identify columns to drop\n",
    "#pops_data = [col for col in df.columns if col.startswith('pops_')]\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "#df = df.drop(columns=pops_data)"
   ],
   "id": "af83ee852c962513"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print(df.columns.tolist())\n",
    "pops_data= [col for col in df if col.startswith('pops_')]\n",
    "print(df[pops_data].columns.tolist())"
   ],
   "id": "a146383f4ca0286b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no POPS measurements, add columns with NaN into dataset.**",
   "id": "ab533ab7279f0963"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# If no POPS\n",
    "new_pops_cols = [\n",
    "    'pops_DateTime', 'pops_Status', 'pops_PartCt', 'pops_BL', 'pops_BLTH', 'pops_STD', 'pops_P',\n",
    "    'pops_TofP', 'pops_POPS_Flow', 'pops_PumpFB', 'pops_LDTemp', 'pops_LaserFB', 'pops_LD_Mon',\n",
    "    'pops_Temp', 'pops_BatV', 'pops_Laser_Current', 'pops_Flow_Set', 'pops_PumpLife_hrs',\n",
    "    'pops_BL_Start', 'pops_TH_Mult', 'pops_nbins', 'pops_logmin', 'pops_logmax', 'pops_Skip_Save',\n",
    "    'pops_MinPeakPts', 'pops_MaxPeakPts', 'pops_RawPts', 'pops_b0', 'pops_b1', 'pops_b2',\n",
    "    'pops_b3', 'pops_b4', 'pops_b5', 'pops_b6', 'pops_b7', 'pops_b8', 'pops_b9', 'pops_b10',\n",
    "    'pops_b11', 'pops_b12', 'pops_b13', 'pops_b14', 'pops_b15', 'pops_PartCon_186', 'pops_pressure',\n",
    "    'pops_total_conc', 'pops_b3_dlogDp', 'pops_b4_dlogDp', 'pops_b5_dlogDp', 'pops_b6_dlogDp', 'pops_b7_dlogDp',\n",
    "    'pops_b8_dlogDp', 'pops_b9_dlogDp', 'pops_b10_dlogDp', 'pops_b11_dlogDp', 'pops_b12_dlogDp', 'pops_b13_dlogDp', 'pops_b14_dlogDp', 'pops_b15_dlogDp'\n",
    "]\n",
    "\n",
    "# Add each column to df with NaN values\n",
    "for col in new_pops_cols:\n",
    "    df[col] = np.nan"
   ],
   "id": "1652c6be7a674295"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.pops import POPS_total_conc_dNdlogDp\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = POPS_total_conc_dNdlogDp(df)"
   ],
   "id": "d586e188e1f1c76a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Apply in case of POPS outlier to replace by NaN at a specific timestamp**",
   "id": "1df48a72783a88b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pops_b_cols = [col for col in df.columns if col.startswith('pops_b')]\n",
    "cols_to_nan = pops_b_cols + ['pops_total_conc']\n",
    "\n",
    "timestamp = pd.Timestamp(\"2025-02-12 07:57:25\")\n",
    "df.loc[timestamp, cols_to_nan] = np.nan"
   ],
   "id": "4469c327f32a676c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Apply in case of intervals with POPS measurements = 0**  ",
   "id": "e695adae4a56f161"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.dates as mdates\n",
    "from matplotlib.widgets import Button\n",
    "import warnings\n",
    "\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib widget\n",
    "plt.close('all')\n",
    "\n",
    "# Plot setup\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "palette = [\"#F54B0F\", \"#415067\"]\n",
    "\n",
    "ax.plot(df.index, df[\"pops_total_conc\"], color=palette[0], linewidth=2)\n",
    "ax.grid(True, ls=\"--\", alpha=0.5)\n",
    "ax.set_ylim(-5, 400)\n",
    "ax.set_ylabel(\"POPS_total_conc (/cm3)\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "ax.xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "# Interaction logic\n",
    "selected_points = []\n",
    "stable_periods = []\n",
    "span_artists = []\n",
    "\n",
    "def onclick(event):\n",
    "    if event.inaxes != ax:\n",
    "        return\n",
    "\n",
    "    # Skip if zoom or pan mode is active\n",
    "    if plt.get_current_fig_manager().toolbar.mode != '':\n",
    "        return\n",
    "        \n",
    "    click_time = mdates.num2date(event.xdata)\n",
    "    selected_points.append(click_time)\n",
    "\n",
    "    ax.plot(event.xdata, event.ydata, 'o', color=palette[1], markersize=8)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    if len(selected_points) == 2:\n",
    "        start, end = sorted(selected_points)\n",
    "        stable_periods.append((start, end))\n",
    "        span = ax.axvspan(start, end, color=palette[1], alpha=0.2)\n",
    "        span_artists.append(span)\n",
    "        selected_points.clear()\n",
    "        fig.canvas.draw()\n",
    "results_df = None\n",
    "\n",
    "def finish_selection(event):\n",
    "    global results_df\n",
    "\n",
    "    if stable_periods:\n",
    "        results_df = pd.DataFrame(stable_periods, columns=['Start_Time', 'End_Time'])\n",
    "        results_df['Duration'] = results_df['End_Time'] - results_df['Start_Time']\n",
    "        \n",
    "        # Optional formatting\n",
    "        results_df['Start_Time'] = results_df['Start_Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        results_df['End_Time'] = results_df['End_Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        print(\"\\nSelected Stable Periods:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "\n",
    "        # Copy to clipboard\n",
    "        results_df.to_clipboard(index=False)\n",
    "        print(\"\\nResults copied to clipboard!\")\n",
    "    else:\n",
    "        print(\"No stable periods selected\")\n",
    "\n",
    "# Add button\n",
    "ax_button = plt.axes([0.82, 0.01, 0.15, 0.05])\n",
    "btn = Button(ax_button, 'Finish Selection', color='lightgoldenrodyellow')\n",
    "btn.on_clicked(finish_selection)\n",
    "\n",
    "# Hook up click handler\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "\n",
    "plt.title(\"Click to select stable periods\")\n",
    "plt.show()\n",
    "\n",
    "print(results_df)"
   ],
   "id": "d09cfb21c0c0a4f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results_df",
   "id": "2d647b89920dd1db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save or load pops mask csv\n",
    "results_df.to_csv(rf'C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\\Processing\\Level1\\Level1_{metadata.flight_date}_Flight_{metadata.flight}_POPSmask.csv', index=False)\n",
    "#results_df = pd.read_csv(rf'C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\\Processing\\Level1\\Level1_{metadata.flight_date}_Flight_{metadata.flight}_POPSmask.csv')\n",
    "\n",
    "# Mask pops data in selected time interval\n",
    "pops_cols = [f'pops_b{i}_dlogDp' for i in range(16)] + ['pops_total_conc']\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    start = row['Start_Time']\n",
    "    end = row['End_Time']\n",
    "    mask = (df.index >= start) & (df.index <= end)\n",
    "    df.loc[mask, pops_cols] = np.nan\n",
    "\n",
    "df.loc[\"2025-02-10 13:47:00\":\"2025-02-10 13:47:15\", 'pops_b3_dlogDp'] "
   ],
   "id": "35c31a74f19dd4b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of POPS concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "\n",
    "       \n",
    "Adds 'pops_total_conc_stp' and 'pops_bX_dlogDp_stp' into df."
   ],
   "id": "118a4a53f5485b06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.pops import POPS_STP_normalization\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = POPS_STP_normalization(df)"
   ],
   "id": "bb9aac78b729b039"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot POPS size distribution and total concentration  \n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "db5d6f0606e06d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.pops import plot_pops_distribution\n",
    "\n",
    "plot_pops_distribution(df, time_start=None, time_end=None)"
   ],
   "id": "b91116c722494825"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mSEMS data processing\n",
    "### mSEMS total concentration calculation\n",
    "\n",
    "*msems_inverted_Bin_ConcX = dN/dlogDp*  \n",
    "*msems_inverted_dN_Bin_ConcX = conc * dlogDp*  \n",
    "*msems_inverted_dN_totalconc = sum of msems_inverted_dN_Bin_ConcX*  \n",
    "\n",
    "Adds 'msems_inverted_dN_Bin_ConcX' and 'msems_inverted_dN_totalconc' into df."
   ],
   "id": "147eb11b632cb4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print(df.columns.tolist())\n",
    "msems_data= [col for col in df if col.startswith('msems_inverted_')]\n",
    "print(df[msems_data].columns.tolist())"
   ],
   "id": "9687dd84906c9730"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no mSEMS measurements, add columns with NaN into dataset.**",
   "id": "e54e233c6ec9d08f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_columns = [\n",
    "    'msems_inverted_DateTime', 'msems_inverted_Temp(C)', 'msems_inverted_Press(hPa)',\n",
    "    'msems_inverted_NumBins', 'msems_inverted_scan_direction',\n",
    "    'msems_inverted_Bin_Lim0', 'msems_inverted_Bin_Lim60',\n",
    "    'msems_inverted_StartTime', 'msems_inverted_EndTime', 'msems_inverted_pressure'\n",
    "]\n",
    "dia_cols   = [f'msems_inverted_Bin_Dia{i}' for i in range(1, 61)]\n",
    "conc_cols  = [f'msems_inverted_Bin_Conc{i}' for i in range(1, 61)]\n",
    "lim_cols   = [f'msems_inverted_Bin_Lim{i}' for i in range(1, 60)]  # 1 to 59\n",
    "\n",
    "new_columns = base_columns + dia_cols + conc_cols + lim_cols\n",
    "\n",
    "for col in new_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan"
   ],
   "id": "fdfc2f12cbe58c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.msems import mSEMS_total_conc_dN\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = mSEMS_total_conc_dN(df)"
   ],
   "id": "28120a12c0d5d452"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of mSEMS concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "Adds 'msems_inverted_Bin_ConcX_stp' and 'msems_inverted_dN_totalconc_stp' to df."
   ],
   "id": "299ee5943978edcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.msems import mSEMS_STP_normalization\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = mSEMS_STP_normalization(df)"
   ],
   "id": "80e325354eddccfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot mSEMS size distribution and total concentration\n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "86949f3fde38a46e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.msems import plot_msems_distribution\n",
    "\n",
    "plot_msems_distribution(df, time_start=None, time_end=None)"
   ],
   "id": "49b9c61ec76d20f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Replace no data or flooded mSEMS measurements by NaN**",
   "id": "ac272081ed744224"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define time range of \"bad\" mSEMS measurements\n",
    "start_time = \"2025-01-27 17:55\"\n",
    "end_time = \"2025-01-27 19:45\"\n",
    "\n",
    "inverted_cols = [\n",
    "    col for col in df.columns \n",
    "    if col.startswith(\"msems_inverted_\") and col != \"msems_inverted_DateTime\"\n",
    "]\n",
    "\n",
    "time_mask = (df.index >= pd.to_datetime(start_time)) & (df.index <= pd.to_datetime(end_time))\n",
    "\n",
    "affected_rows = set()\n",
    "\n",
    "# Apply only within the time range\n",
    "for col in inverted_cols:\n",
    "    col_mask = df[col].map(lambda x: isinstance(x, (int, float)) and not np.isnan(x))\n",
    "    full_mask = time_mask & col_mask\n",
    "    affected_rows.update(df.index[full_mask])\n",
    "    df.loc[full_mask, col] = np.nan\n",
    "\n",
    "# Count affected rows\n",
    "print(f\"{len(affected_rows)} rows had numeric value replaced by NaN in 'msems_inverted_...' columns within the time range.\")"
   ],
   "id": "6c311b6b49cb51c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mCDA data processing\n",
    "### mCDA bin concentrations, total concentration and normalization per bin width\n",
    "\n",
    "For bins 1 to 256 :  \n",
    "*mcda_dataB X = raw counts*  \n",
    "*mcda_dataB X_dN = counts / (flow rate * sampling interval) = concentration*  \n",
    "*mcda_dN_totalconc = sum of mcda_dataBX_dN*  \n",
    "*mcda_dataB X_dN_dlogDp = dN/dlogDp = mcda_dataBX_dN / dlogDp*\n",
    "\n",
    "Adds 'mcda_dataB X_dN', 'mcda_dN_totalconc' and 'mcda_dataB X_dN_dlogDp' into df."
   ],
   "id": "7075446457f8008c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Identify columns to drop\n",
    "#mcda_data = [col for col in df.columns if col.startswith('mcda_')]\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "#df = df.drop(columns=mcda_data)"
   ],
   "id": "3a353cda321b8a69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# print(df.columns.tolist())\n",
    "mcda_data= [col for col in df if col.startswith('mcda_')]\n",
    "print(df[mcda_data].columns.tolist())"
   ],
   "id": "216f333cf8d9bb0b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no mCDA measurements, add columns with NaN into dataset.**",
   "id": "5b31bffe891d6749"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Identify the position of the last column that starts with 'msems_'\n",
    "msems_cols = [col for col in df.columns if col.startswith('msems_')]\n",
    "if not msems_cols:\n",
    "    raise ValueError(\"No columns starting with 'msems_' were found in the DataFrame.\")\n",
    "\n",
    "last_msems_index = df.columns.get_loc(msems_cols[-1])\n",
    "\n",
    "# Define your new columns\n",
    "first_cols = ['mcda_DateTime', 'mcda_timestamp_x', 'mcda_set_flow', 'mcda_actual_flow', 'mcda_flow_diff', 'mcda_power %']  \n",
    "mcda_dataB_cols = [f'mcda_dataB {i}' for i in range(1, 513)]\n",
    "mcda_dataB_dN_cols = [f'mcda_dataB {i}_dN' for i in range(1, 257)]\n",
    "mcda_dataB_dN_dlogDp_cols = [f'mcda_dataB {i}_dN_dlogDp' for i in range(1, 257)]\n",
    "last_cols = [\n",
    "    'mcda_pcount', 'mcda_pm 1', 'mcda_pm 2.5', 'mcda_pm 4', 'mcda_pm 10',\n",
    "    'mcda_pmtot', 'mcda_timestamp_y', 'mcda_Temperature', 'mcda_Pressure', 'mcda_RH',\n",
    "    'mcda_pmav', 'mcda_offset1', 'mcda_offset2', 'mcda_calib1', 'mcda_calib2',\n",
    "    'mcda_measurement_nbr', 'mcda_pressure', 'mcda_dN_totalconc'\n",
    "]\n",
    "mcda_cols = first_cols + mcda_dataB_cols + mcda_dataB_dN_cols + mcda_dataB_dN_dlogDp_cols + last_cols\n",
    "\n",
    "# Create a DataFrame with those new columns (filled with NaN)\n",
    "mcda_df = pd.DataFrame(np.nan, index=df.index, columns=mcda_cols)\n",
    "\n",
    "# Insert the new columns into df at the correct position\n",
    "df = pd.concat([df.iloc[:, :last_msems_index+1], mcda_df, df.iloc[:, last_msems_index+1:]], axis=1)"
   ],
   "id": "67fd0d16b94ff4f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.mcda_instrument import mcda_concentration_calculations\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = mcda_concentration_calculations(df)"
   ],
   "id": "8f700378ce62dd64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of mCDA concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "Adds 'mcda_dataB X_dN_dlogDp_stp' and 'mcda_dN_totalconc_stp' to df."
   ],
   "id": "56c4d32b9ad1ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.mcda_instrument import mCDA_STP_normalization\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = mCDA_STP_normalization(df)"
   ],
   "id": "ece6d1b41477060b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot mCDA size distribution and total concentration\n",
    "\n",
    "STP normalized bin concentrations and total concentration  "
   ],
   "id": "5b34c954802c595d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.mcda_instrument import Midpoint_diameter_list as Midpoint_diameter_list\n",
    "from helikite.instruments.mcda_instrument import plot_mcda_distribution\n",
    "\n",
    "plot_mcda_distribution(df, Midpoint_diameter_list, time_start=None, time_end=None)"
   ],
   "id": "602ee1c887f1b24a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Vertical droplet size distribution**",
   "id": "678188961aafeca5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.mcda_instrument import Midpoint_diameter_list as Midpoint_diameter_list\n",
    "from helikite.instruments.mcda_instrument import plot_mcda_vertical_distribution\n",
    "\n",
    "plot_mcda_vertical_distribution(df, Midpoint_diameter_list)"
   ],
   "id": "51467e31722dff94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CPC3007 data processing",
   "id": "c07f591ac7958886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(df['cpc_totalconc_raw'])",
   "id": "bf983df7152c819"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no CPC measurements, add columns with NaN into dataset.**",
   "id": "96483203021c8ee1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['cpc_totalconc_raw'] = np.nan",
   "id": "921c4721daa480cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of CPC3007 concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "\n",
    "       \n",
    "Adds 'CPC_total_N_stp' into df."
   ],
   "id": "a0d58a797b9f1e52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.cpc3007 import CPC\n",
    "%matplotlib ipympl\n",
    "\n",
    "df = CPC.CPC_STP_normalization(df)"
   ],
   "id": "bdabe791c7d63538"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[['cpc_totalconc_raw', 'cpc_totalconc_stp']].head()",
   "id": "a980f7210adc7fb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter data check",
   "id": "86b2ee7da15b1716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# NO FILT DATA FROM FC --> READ IN THE FILT FILE AND PASTE IT INTO DF WITH CORRECT NAMES !!!!!",
   "id": "61f4d9a7005180aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "filt = pd.read_csv(r\"C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\\2024-2025_Sorted\\2025-01-27_A\\250127A3.TXT\", skiprows=13, delimiter='\\t')  # or use sep=',' if it's CSV\n",
    "\n",
    "date_str = filt['#YY/MM/DD'].str.strip()\n",
    "time_str = filt['HR:MN:SC'].str.strip()\n",
    "combined = date_str + ' ' + time_str\n",
    "filt['datetime'] = pd.to_datetime(combined, format='%y/%m/%d %H:%M:%S')\n",
    "filt = filt.set_index('datetime', drop=False)\n",
    "filt.columns = 'flight_computer_F_' + filt.columns.astype(str)\n",
    "\n",
    "filt"
   ],
   "id": "d0a8e13df62cefd4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = df.join(filt, how='left')\n",
    "df"
   ],
   "id": "81d7c9d40ed7236e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.processing.post.level1 import filter_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.close('all')\n",
    "%matplotlib ipympl\n",
    "\n",
    "filter_data(df)"
   ],
   "id": "fb8925de665549fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**In case of broken filters, replace filter positions by 1.**",
   "id": "4546d26a34730941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['flight_computer_F_cur_pos'] = 1\n",
    "df['flight_computer_F_pump_pw'] = 0"
   ],
   "id": "ff8c71e83d28b7aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.loc[df['flight_computer_F_cur_pos'] == 0, 'flight_computer_F_cur_pos'] = 1\n",
    "df.loc[df['flight_computer_F_cur_pos'] == 2, 'flight_computer_F_cur_pos'] = 1\n",
    "df.loc[df['flight_computer_F_cur_pos'] == 4, 'flight_computer_F_cur_pos'] = 1"
   ],
   "id": "9fae097ebef3b987"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "broken_filter_start = pd.Timestamp(\"2025-02-11 15:44:14\")\n",
    "broken_filter_end = pd.Timestamp(\"2025-02-11 16:11:39\")\n",
    "df.loc[df['flight_computer_F_cur_pos'] == 0, 'flight_computer_F_cur_pos'] = 1\n",
    "\n",
    "df.loc[(df.index >= broken_filter_start) & (df.index <= broken_filter_end), 'flight_computer_F_cur_pos'] = 2.0\n",
    "df.loc[(df.index >= broken_filter_start) & (df.index <= broken_filter_end), 'flight_computer_F_pump_pw'] = 37.0\n",
    "df['flight_computer_F_cur_pos']"
   ],
   "id": "9fd2cf89140a0604"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TAPIR data check",
   "id": "321e1abebd66bca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tapir_data = [col for col in df if col.startswith('tapir_')]\n",
    "print(df[tapir_data].columns.tolist())"
   ],
   "id": "2fcbbccc8e51fd8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**If no TAPIR measurements, add columns with NaN into dataset.**",
   "id": "c313686de8d8d6d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for col in [\n",
    "    'tapir_GL', 'tapir_Lat', 'tapir_Le', 'tapir_Lon', 'tapir_Lm',\n",
    "    'tapir_speed', 'tapir_route', 'tapir_TP', 'tapir_Tproc1', 'tapir_Tproc2',\n",
    "    'tapir_Tproc3', 'tapir_Tproc4', 'tapir_TH', 'tapir_Thead1', 'tapir_Thead2',\n",
    "    'tapir_Thead3', 'tapir_Thead4', 'tapir_TB', 'tapir_Tbox'\n",
    "]:\n",
    "    df[col] = np.nan\n",
    "\n",
    "df[['tapir_GL', 'tapir_Lat', 'tapir_Le']].head()"
   ],
   "id": "725c4f7c7755375a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df",
   "id": "9edaee220a8f1cd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data quicklooks",
   "id": "3c3647b34b3b6a3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.processing.post.level1 import flight_profiles_1\n",
    "\n",
    "# Limits for x-axis (T, RH, mSEMS, CPC, POPS, mCDA, WS, WD)\n",
    "custom_xlim = {\n",
    "    'ax1': (-6, 2),\n",
    "    'ax2': (60, 100),\n",
    "    'ax3': (0, 1200), \n",
    "    'ax4': (0, 1200),\n",
    "    'ax5': (0, 60),\n",
    "    'ax6': (0, 60),\n",
    "    'ax7': (0, 12)\n",
    "}\n",
    "\n",
    "custom_xticks = {\n",
    "    'ax1': np.arange(-6, 3, 2),\n",
    "    'ax2': np.arange(60, 101, 10), \n",
    "    'ax3': np.arange(0, 1201, 200),\n",
    "    'ax4': np.arange(0, 1201, 200),\n",
    "    'ax5': np.arange(0, 61, 10),\n",
    "    'ax6': np.arange(0, 61, 10),\n",
    "    'ax7': np.arange(0, 13, 3)\n",
    "}\n",
    "\n",
    "# Plot title\n",
    "custom_title = f'Flight {metadata.flight} ({metadata.flight_date}_A) [Level 1]'\n",
    "\n",
    "fig = flight_profiles_1(df, metadata, xlims=custom_xlim, xticks=custom_xticks, fig_title=custom_title)\n",
    "\n",
    "# Save the figure after plotting\n",
    "#folder_path = r'C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\\Processing\\Level1'\n",
    "#filename = f'Level1_{metadata.flight_date}_A_Flight_{metadata.flight}.png'\n",
    "#save_path = f'{folder_path}\\\\{filename}'\n",
    "#print(\"Saving figure to:\", save_path)\n",
    "#fig.savefig(save_path, dpi=300, bbox_inches='tight')"
   ],
   "id": "ca8484210603c237"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TEMPORAL PLOT OF FLIGHT with POPS and mSEMS HEAT MAPS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcols\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "\n",
    "# Create figure with 3 subplots, sharing the same x-axis\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True, gridspec_kw={'height_ratios': [1, 1, 1, 1]})\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "\"\"\" SET THE TITLE OF THE PLOT (FLIGHT N° with DATE_X) \"\"\"\n",
    "# 'i' will automatically be replaced by the set flight number\n",
    "# '_X' has to be changed manually in function of the flight index of the day (A, B, ...)\n",
    "fig.suptitle(f'Flight {metadata.flight} ({metadata.flight_date}_A) [Level 1]', fontsize=16, fontweight='bold', y=0.91)\n",
    "\n",
    "### SUBPLOT 1: Altitude vs. Time\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df.index, df['Altitude'], color='black', linewidth=2, label='Altitude')\n",
    "\n",
    "ax1.set_ylabel('Altitude (m)', fontsize=12, fontweight='bold')\n",
    "ax1.tick_params(axis='y', labelsize=11)\n",
    "ax1.grid(True, linestyle='--', linewidth=0.5)\n",
    "ax1.tick_params(axis='x', labelbottom=False)\n",
    "ax1.set_ylim(-40, df['Altitude'].max() * 1.04)\n",
    "\n",
    "### SUBPLOT 2: mSEMS heatmmap & total concentration\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Get diameter bin averages\n",
    "start_dia = 'msems_inverted_Bin_Dia1'\n",
    "end_dia = 'msems_inverted_Bin_Dia60'\n",
    "bin_diameter_averages = df.loc[:, start_dia:end_dia].mean()\n",
    "\n",
    "# Get concentration data\n",
    "start_conc = 'msems_inverted_Bin_Conc1_stp'\n",
    "end_conc = 'msems_inverted_Bin_Conc60_stp'\n",
    "counts = df.loc[:, start_conc:end_conc]\n",
    "counts.index = df.index\n",
    "counts = counts.astype(float).dropna(how='any')\n",
    "counts = counts.clip(lower=1)\n",
    "\n",
    "# Create 2D grid\n",
    "xx, yy = np.meshgrid(counts.index.values, bin_diameter_averages)\n",
    "\n",
    "# Contour plot\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=1000)\n",
    "mesh = ax2.pcolormesh(xx, yy, counts.values.T, cmap='viridis', norm=norm, shading=\"gouraud\")\n",
    "\n",
    "# Colorbar\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = inset_axes(ax2, width=\"1.5%\", height=\"100%\", loc='lower left',\n",
    "                 bbox_to_anchor=(1.08, -0.025, 1, 1), bbox_transform=ax2.transAxes)\n",
    "cb = fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "cb.set_label('dN/dlogD$_p$ (cm$^{-3}$)', fontsize=13, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "\n",
    "# Add Secondary Y-axis for Total Concentration\n",
    "ax2_right = ax2.twinx()\n",
    "total_conc = df['msems_inverted_dN_totalconc_stp']\n",
    "ax2_right.scatter(df.index, total_conc, color='red', marker='.')\n",
    "ax2_right.set_ylabel('mSEMS conc (cm$^{-3}$)', fontsize=12, fontweight='bold', color='red', labelpad=8)\n",
    "ax2_right.tick_params(axis='y', labelsize=11, colors='red')\n",
    "#ax2_right.set_ylim(0, total_conc.max() * 1.1)\n",
    "\n",
    "# Labels and limits\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_ylabel('Part. Diameter (nm)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylim(8, 236)\n",
    "ax2.grid(True, linestyle='--', alpha=0.6, axis='x')\n",
    "\n",
    "\n",
    "### SUBPLOT 3: POPS heatmap & total concentration \n",
    "ax3 = axes[2]\n",
    "\n",
    "# Define pops_dlogDp variable from Hendix documentation\n",
    "pops_dia = [\n",
    "    149.0801282, 162.7094017, 178.3613191, 195.2873341, \n",
    "    212.890625, 234.121875, 272.2136986, 322.6106374, \n",
    "    422.0817873, 561.8906456, 748.8896681, 1054.138693,\n",
    "    1358.502538, 1802.347716, 2440.99162, 3061.590212\n",
    "]\n",
    "\n",
    "pops_dlogDp = [\n",
    "    0.036454582, 0.039402553, 0.040330922, 0.038498955,\n",
    "    0.036550107, 0.045593506, 0.082615487, 0.066315868,\n",
    "    0.15575785, 0.100807113, 0.142865049, 0.152476328,\n",
    "    0.077693935, 0.157186601, 0.113075192, 0.086705426\n",
    "]\n",
    "\n",
    "# Define the range of columns for POPS concentration\n",
    "start_conc = 'pops_b3_dlogDp_stp'\n",
    "end_conc = 'pops_b15_dlogDp_stp'\n",
    "\n",
    "# Get POPS concentration data\n",
    "pops_counts = df.loc[:, start_conc:end_conc]\n",
    "pops_counts = pops_counts.set_index(df.index).astype(float)\n",
    "\n",
    "# Create 2D grid\n",
    "#pops_dia = np.logspace(np.log10(180), np.log10(3370), num=pops_counts.shape[1])\n",
    "bin_diameters = pops_dia[3:16]\n",
    "xx, yy = np.meshgrid(pops_counts.index.values, bin_diameters)\n",
    "\n",
    "# Heatmap\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=300)\n",
    "mesh = ax3.pcolormesh(xx, yy, pops_counts.values.T, cmap='viridis', norm=norm, shading=\"gouraud\")\n",
    "\n",
    "# Colorbar\n",
    "divider = make_axes_locatable(ax3)\n",
    "cax = inset_axes(ax3, width=\"1.5%\", height=\"100%\", loc='lower left',\n",
    "                 bbox_to_anchor=(1.08, -0.025, 1, 1), bbox_transform=ax3.transAxes)\n",
    "cb = fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "cb.set_label('dN/dlogD$_p$ (cm$^{-3}$)', fontsize=12, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "\n",
    "# Labels and grid\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_ylabel('Part. Diameter (nm)', fontsize=12, fontweight='bold')\n",
    "ax3.tick_params(axis='y', labelsize=11)\n",
    "ax3.grid(True, linestyle='--', linewidth=0.5, axis='x')\n",
    "ax3.grid(False, axis='y')\n",
    "ax3.set_ylim(180, 3370)\n",
    "\n",
    "# Add Secondary Y-axis for Total POPS Concentration\n",
    "ax3_right = ax3.twinx()\n",
    "ax3_right.plot(df.index, df['pops_total_conc_stp'], color='red', linewidth=2, label='Total POPS Conc.')\n",
    "ax3_right.set_ylabel('POPS conc (cm$^{-3}$)', fontsize=12, fontweight='bold', color='red', labelpad=8)\n",
    "ax3_right.tick_params(axis='y', labelsize=11, colors='red')\n",
    "ax3_right.spines['right'].set_color('red')\n",
    "ax3_right.set_ylim(-20, df['pops_total_conc_stp'].max() * 1.1)\n",
    "\n",
    "### Subplot 4: mCDA heatmap & total concentration \n",
    "ax4 = axes[3]\n",
    "\n",
    "# Midpoint diameters \n",
    "Midpoint_diameter_list = np.array([\n",
    "    0.244381, 0.246646, 0.248908, 0.251144, 0.253398, 0.255593, 0.257846, 0.260141, 0.262561, 0.265062, 0.267712, 0.270370, 0.273159, 0.275904, 0.278724, 0.281554, 0.284585, 0.287661, 0.290892, 0.294127, 0.297512, 0.300813, 0.304101, 0.307439,\n",
    "    0.310919, 0.314493, 0.318336, 0.322265, 0.326283, 0.330307, 0.334409, 0.338478, 0.342743, 0.347102, 0.351648, 0.356225, 0.360972, 0.365856, 0.371028, 0.376344, 0.382058, 0.387995, 0.394223, 0.400632, 0.407341, 0.414345, 0.421740, 0.429371,\n",
    "    0.437556, 0.446036, 0.454738, 0.463515, 0.472572, 0.481728, 0.491201, 0.500739, 0.510645, 0.520720, 0.530938, 0.541128, 0.551563, 0.562058, 0.572951, 0.583736, 0.594907, 0.606101, 0.617542, 0.628738, 0.640375, 0.652197, 0.664789, 0.677657,\n",
    "    0.691517, 0.705944, 0.721263, 0.736906, 0.753552, 0.770735, 0.789397, 0.808690, 0.829510, 0.851216, 0.874296, 0.897757, 0.922457, 0.948074, 0.975372, 1.003264, 1.033206, 1.064365, 1.097090, 1.130405, 1.165455, 1.201346, 1.239589, 1.278023,\n",
    "    1.318937, 1.360743, 1.403723, 1.446000, 1.489565, 1.532676, 1.577436, 1.621533, 1.667088, 1.712520, 1.758571, 1.802912, 1.847836, 1.891948, 1.937088, 1.981087, 2.027604, 2.074306, 2.121821, 2.168489, 2.216644, 2.263724, 2.312591, 2.361099,\n",
    "    2.412220, 2.464198, 2.518098, 2.571786, 2.628213, 2.685162, 2.745035, 2.805450, 2.869842, 2.935997, 3.005175, 3.074905, 3.148598, 3.224051, 3.305016, 3.387588, 3.476382, 3.568195, 3.664863, 3.761628, 3.863183, 3.965651, 4.072830, 4.179050,\n",
    "    4.289743, 4.400463, 4.512449, 4.621025, 4.731530, 4.839920, 4.949855, 5.057777, 5.169742, 5.281416, 5.395039, 5.506828, 5.621488, 5.734391, 5.849553, 5.962881, 6.081516, 6.200801, 6.322133, 6.441786, 6.565130, 6.686935, 6.813017, 6.938981,\n",
    "    7.071558, 7.205968, 7.345185, 7.483423, 7.628105, 7.774385, 7.926945, 8.080500, 8.247832, 8.419585, 8.598929, 8.780634, 8.973158, 9.167022, 9.372760, 9.582145, 9.808045, 10.041607, 10.287848, 10.537226, 10.801172, 11.068405, 11.345135,\n",
    "    11.621413, 11.910639, 12.200227, 12.492929, 12.780176, 13.072476, 13.359067, 13.651163, 13.937329, 14.232032, 14.523919, 14.819204, 15.106612, 15.402110, 15.695489, 15.998035, 16.297519, 16.610927, 16.926800, 17.250511,\n",
    "    17.570901, 17.904338, 18.239874, 18.588605, 18.938763, 19.311505, 19.693678, 20.093464, 20.498208, 20.927653, 21.366609, 21.827923, 22.297936, 22.802929, 23.325426, 23.872344, 24.428708, 25.016547, 25.616663, 26.249815,\n",
    "    26.888493, 27.563838, 28.246317, 28.944507, 29.626186, 30.323440, 31.005915, 31.691752, 32.353900, 33.030123, 33.692286, 34.350532, 34.984611, 35.626553, 36.250913, 36.878655, 37.489663, 38.121550, 38.748073, 39.384594, \n",
    "    40.008540, 40.654627, 41.292757, 41.937789, 42.578436\n",
    "])\n",
    "\n",
    "# Prepare data\n",
    "counts = df.loc[:, 'mcda_dataB 1_dN_dlogDp_stp':'mcda_dataB 256_dN_dlogDp_stp']\n",
    "counts = counts.set_index(df.index)\n",
    "counts = counts.astype(float)\n",
    "counts[counts == 0] = np.nan\n",
    "\n",
    "bin_diameters = Midpoint_diameter_list\n",
    "xx, yy = np.meshgrid(counts.index.values, bin_diameters)\n",
    "Z = counts.values.T\n",
    "\n",
    "# Plot heatmap\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=50)\n",
    "mesh = ax4.pcolormesh(xx, yy, Z, cmap='viridis', norm=norm, shading=\"gouraud\")\n",
    "\n",
    "# Colorbar\n",
    "divider = make_axes_locatable(ax4)\n",
    "cax = inset_axes(ax4, width=\"1.5%\", height=\"100%\", loc='lower left',\n",
    "                 bbox_to_anchor=(1.08, -0.025, 1, 1), bbox_transform=ax4.transAxes)\n",
    "cb = fig.colorbar(mesh, cax=cax, orientation='vertical')\n",
    "cb.set_label('dN/dlogD$_p$ (cm$^{-3}$)', fontsize=12, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=11)\n",
    "\n",
    "# Total concentration\n",
    "ax4_right = ax4.twinx()\n",
    "total_conc = df['mcda_dN_totalconc_stp']\n",
    "ax4_right.plot(df.index, total_conc, color='red', linewidth=2)\n",
    "ax4_right.set_ylabel('mCDA conc (cm$^{-3}$)', fontsize=12, fontweight='bold', color='red', labelpad=15)\n",
    "ax4_right.tick_params(axis='y', labelsize=11, colors='red')\n",
    "#ax4_right.set_ylim(0, total_conc.max() * 2)\n",
    "#ax4_right.set_xlim(ax4.get_xlim())\n",
    "\n",
    "# Axis styling\n",
    "ax4.set_yscale('log')\n",
    "ax4.set_ylabel('Part. Diameter (μm)', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylim(0.4, 20)\n",
    "ax4.grid(True, linestyle='--', linewidth=0.5, axis='x')\n",
    "ax4.grid(False, axis='y')\n",
    "\n",
    "# Legend for secondary y-axis\n",
    "#ax2_right.legend(['mSEMS total conc.'], loc='upper right', fontsize=11, frameon=False)\n",
    "#ax3_right.legend(['POPS total conc.'], loc='upper right', fontsize=11, frameon=False)\n",
    "#ax4_right.legend(['mCDA total conc.'], loc='upper right', fontsize=11, frameon=False)\n",
    "\n",
    "# X-axis formatting for all subplots\n",
    "ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax4.xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
    "ax4.set_xlabel('Time', fontsize=13, fontweight='bold', labelpad=10)\n",
    "ax4.tick_params(axis='x', rotation=90, labelsize=11)\n",
    "\n",
    "\n",
    "\"\"\" SET TIME RANGE (DATE + TIME) \"\"\"\n",
    "#ax3.set_xlim(pd.Timestamp('2025-02-12T07:55:00'), pd.Timestamp('2025-02-12T10:20:00'))\n",
    "\n",
    "\"\"\" SAVE PLOT \"\"\"\n",
    "#folder_path = r'C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\\Processing\\Level1'\n",
    "#filename = f'Level1_{metadata.flight_date}_A_SizeDistr_Flight_{metadata.flight}.png'\n",
    "#save_path = f'{folder_path}\\\\{filename}'\n",
    "#print(\"Saving figure to:\", save_path)\n",
    "#fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9d5dd6dcba9a6960"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Level 1\n",
    "**Save file containing all the columns (processed)**"
   ],
   "id": "78a807741d0856b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\" CHANGE NAME OF OUTPUT FILE \"\"\"\n",
    "\n",
    "df.to_csv(r'C:\\Users\\temel\\Desktop\\EERL\\Campaigns\\03_ORACLES\\Neumayer_2024\\Data\\Processing\\Level1\\level1_2025-01-27_A.csv', index=True)"
   ],
   "id": "219b2f4b5ae341e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random code bits\n",
    "### Remove outliers from the Smart Tether WS and WD datapoints\n",
    "\n",
    "This is a **sliding-window median filter** used for **outlier detection and removal**.\n",
    "- Look at a window of neighboring values around each data point (10 neighboring values)\n",
    "- Compare the current point to the median of this window.\n",
    "- If the point is significantly different (>35% away from the median), it's treated as an outlier and **replaced with NaN**.\n",
    "\n",
    "Applied on WS, the corresponding WD datapoints are then also removed."
   ],
   "id": "2470efabe3fa396f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from helikite.instruments.smart_tether import wind_outlier_removal\n",
    "%matplotlib ipympl\n",
    "\n",
    "df_filtered = wind_outlier_removal(df)"
   ],
   "id": "de3c1720de09aaed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**IF THE FILTER APPLIES CORRECTLY** : save the filtered WS and WD data back into th original dataframe",
   "id": "d45f63278226e59a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the filtered data back into th original dataframe\n",
    "df['smart_tether_Wind (m/s)'] = df_filtered['smart_tether_Wind (m/s)']\n",
    "df['smart_tether_Wind (degrees)'] = df_filtered['smart_tether_Wind (degrees)']\n",
    "print(\"Filtered data saved to the original dataframe.\")"
   ],
   "id": "5ca7c25c04e1318c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metadata dictionary",
   "id": "4af5483fff42808a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Otherwise, to make a dictionary from the metadata:\n",
    "metadata_dict = metadata.model_dump()\n",
    "\n",
    "# Then use it as a normal Python dictionary\n",
    "metadata_dict['flight_date']"
   ],
   "id": "ce2b4a26d273c5e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# The dataframe is unpacked into the 'df' variable from that function above\n",
    "df"
   ],
   "id": "b6f8adf6435424aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GPS coordinate check",
   "id": "2bec36e238d10374"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# First y-axis for Longitude\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Longitude', color=color)\n",
    "ax1.plot(df.index, df['flight_computer_Long'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Second y-axis for Latitude\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Latitude', color=color)\n",
    "ax2.plot(df.index, df['flight_computer_Lat'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Longitude and Latitude over Time')\n",
    "plt.show()\n"
   ],
   "id": "f10cd728f89505af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_dm_to_dd(dm_value, direction):\n",
    "    if pd.isna(dm_value):\n",
    "        return None\n",
    "    degrees = int(dm_value / 100)\n",
    "    minutes = dm_value - degrees * 100\n",
    "    dd = degrees + minutes / 60\n",
    "    if direction in ['S', 'W']:\n",
    "        dd *= -1\n",
    "    return dd\n",
    "\n",
    "# Apply conversion to the entire column\n",
    "df['latitude_dd'] = df['flight_computer_Lat'].apply(lambda x: convert_dm_to_dd(x, 'S'))\n",
    "df['longitude_dd'] = df['flight_computer_Long'].apply(lambda x: convert_dm_to_dd(x, 'W'))\n",
    "df['latitude_dd']"
   ],
   "id": "4dcb8413ad412244"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Export TAPIR data for Delphine ",
   "id": "53f219f61d859847"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df['mcda_dN_totalconc_stp'] = np.nan",
   "id": "d75e673f27d98e77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a new DataFrame with the same DateTime index as df\n",
    "df_tapir = df.loc[:, ['Altitude', 'Average_Temperature', 'Temperature_ground', 'mcda_dN_totalconc_stp'] + \n",
    "                  [col for col in df.columns if col.startswith('tapir_')]]\n",
    "df_tapir['Altitude'] = df_tapir['Altitude'].round(2)\n",
    "df_tapir['Average_Temperature'] = df_tapir['Average_Temperature'].round(2)\n",
    "df_tapir['mcda_dN_totalconc_stp'] = df_tapir['mcda_dN_totalconc_stp'].round(2)\n",
    "\n",
    "df_tapir"
   ],
   "id": "e04e2450246cbe73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Example metadata as a dictionary (you can adjust this to your actual metadata object)\n",
    "metadata_lines = {\n",
    "    'Flight date' : metadata.flight_date,\n",
    "    'Flight number' : metadata.flight,\n",
    "    'Takeoff time' : metadata.takeoff_time,\n",
    "    'Landing time' : metadata.landing_time,\n",
    "    'Average_Temperature (in °C)' : 'average T from two temperature sensors',\n",
    "    'Temperature_ground (in K)' : 'extrapolated ground temperature based on T at takeoff and landing',\n",
    "    'mcda_dN_totalconc_stp (cm-3)' : 'droplet total concentration',\n",
    "    'Note' : 'there are two \"peaks\" in the temperature profile, I am however not yet sure if they are significant or outliers'\n",
    "}\n",
    "\n",
    "# Construct the dynamic filename\n",
    "filename = f\"{metadata.flight_date}_Flight{metadata.flight}_TAPIR.txt\"\n",
    "\n",
    "# Define your output directory (use raw string if needed)\n",
    "output_dir = r'C:\\Users\\temel\\helikite-data-processing\\Yolanda-helikite-data-processing\\notebooks\\tapir'\n",
    "\n",
    "# Combine the path and filename\n",
    "output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "# Save the file\n",
    "with open(output_path, 'w', newline='') as f:\n",
    "    for key, value in metadata_lines.items():\n",
    "        f.write(f\"# {key}: {value}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    df_tapir.to_csv(f, index=True)"
   ],
   "id": "85f3fc39b0d551b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b01ece5433dc3538"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
