{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data processing - Level 1\n",
    "Code written by Radiance and Yolanda (with the help of ChatGPT)"
   ],
   "id": "b2a582f6a53b6b34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib ipympl"
   ],
   "id": "851c7f4fdda59629",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "from helikite.config import load_config\n",
    "from helikite.constants import constants\n",
    "\n",
    "logging.basicConfig(level=constants.LOGLEVEL_CONSOLE)\n",
    "config = load_config(constants.INPUTS_FOLDER / constants.CONFIG_FILE)\n",
    "\n",
    "# define your input and output directories here\n",
    "input_level0_dir = config.processing_dir / \"Level0\"\n",
    "output_level1_dir = config.processing_dir / \"Level1\"\n",
    "output_level1_dir.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "ea23e21f728e6af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T17:49:26.500384Z",
     "start_time": "2025-12-12T17:49:24.980692Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "a2a251ecd14cac9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.metadata.utils import load_parquet\n",
    "\n",
    "df_level0, metadata = load_parquet(input_level0_dir / f\"level0_{config.flight_basename}.parquet\")"
   ],
   "id": "b5677b688b904c24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "metadata",
   "id": "ced83562695d9b4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T17:49:27.558007Z",
     "start_time": "2025-12-12T17:49:27.545043Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Example commands to output different individual elements of the dataset**  \n",
    "\n",
    "*To use individual fields, just use the object (.) notation, for example*  \n",
    "  \n",
    "print(metadata.flight_date)  \n",
    "print(metadata.landing_time)  \n",
    "metadata.takeoff_time\n",
    "\n",
    "flight_computer_columns = [col for col in df.columns if col.startswith(\"flight_computer_\")]  \n",
    "print(flight_computer_columns)  \n",
    "\n",
    "smart_tether_columns = [col for col in df.columns if col.startswith(\"smart_tether_\")]  \n",
    "print(smart_tether_columns)"
   ],
   "id": "171e6ebf2d31bd27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DataProcessor class",
   "id": "689484c4e41f30e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.classes.output_schemas import OutputSchemas\n",
    "from helikite.classes.data_processing_level1 import DataProcessorLevel1\n",
    "\n",
    "data_processor = DataProcessorLevel1(getattr(OutputSchemas, config.output_schema), df_level0, metadata)\n",
    "data_processor.state()"
   ],
   "id": "4b871f0bfcc3f0e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Processing missing instruments\n",
    "**If no measurements are available for an instrument, add columns with NaNs into the dataset.**"
   ],
   "id": "a2a1f04afdd7d7ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.add_missing_columns()",
   "id": "c5117bf29648caa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Outlier removal",
   "id": "aabdf6540bcb6417"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "outliers_file = output_level1_dir / f\"level1_{config.flight_basename}_outliers.csv\"",
   "id": "60f5511a9e48c5dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`data_processor.detect_outliers()` marks points that are outside the interquartile range (IQR) using the provided IQR factor.\n",
    " When columns are not specified, default columns are used. When `acceptable_ranges` are not specified, default ranges are applied."
   ],
   "id": "acab2b75ae5bce6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.detect_outliers(outliers_file, columns=None, acceptable_ranges=None, iqr_factor=5)\n",
    "data_processor.state()"
   ],
   "id": "13fd24bd9babb2bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```data_processor.choose_outliers()``` loads all the data, plots an individual variable, and then saves a CSV of any outliers that are chosen as True. This outlier CSV will be later used by ```data_processor.set_outliers_to_nan()``` to mask the values in the original dataframe.\n",
    "\n",
    "_Note: No data is changed in the input dataframe._\n",
    "\n",
    "In a first time, check the **'flight_computer_pressure'** against **'flight_computer_time'** as well as **'flight_computer_Out1_T'**, **'flight_computer_Out2_T'**, **'flight_computer_Out1_H'** and **'flight_computer_Out2_H'**.\n",
    "Then check **'smart_tether_Wind (m/s)'**. The WD values corresponding to the WS outliers will automatically also be set as outliers – no need to manually select **'smart_tether_Wind (degrees)'** outliers (if ```use_coupled_columns``` is ```True```).\n",
    "If needed, remove **'flight_computer_Lat'** outliers. The Long values corresponding to the Lat outliers will automatically also be set as outliers – no need to manually select **'flight_computer_Long'** outliers (if ```use_coupled_columns``` is ```True```).\n",
    "\n",
    "### Coupled columns\n",
    "To check which columns are coupled, see output of ```data_processor.state()```. To add new groups of coupled columns to an instrument, pass the list of all the groups to argument ```coupled_columns```  of the\n",
    "instrument instance. For example:\n",
    "```python\n",
    "flight_computer_v1 = FlightComputerV1(\n",
    "    name=\"flight_computer\",\n",
    "    ...\n",
    "    coupled_columns=[\n",
    "        ('flight_computer_TEMP1', 'flight_computer_RH1'),\n",
    "        ('flight_computer_TEMP2', 'flight_computer_RH2'),\n",
    "    ]\n",
    ")\n",
    "```\n",
    " For the coupled columns to be updated, restart the kernel and rerun the cells."
   ],
   "id": "358294bf4668bd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.choose_outliers(y=f\"{data_processor.reference_instrument.name}_pressure\", outliers_file=outliers_file, use_coupled_columns=True)\n",
    "# data_processor.choose_outliers(y=\"pops_pressure\", outliers_file=outliers_file, use_coupled_columns=True)\n",
    "# data_processor.choose_outliers(y=\"cpc_DateTime\", outliers_file=outliers_file, use_coupled_columns=True)"
   ],
   "id": "f51630119c2491a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T17:49:34.152120Z",
     "start_time": "2025-12-12T17:49:33.932507Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "If coupled columns were not specified when choosing outliers, ensure consistency manually.\n",
    "If coupled columns were specified, this adjustment is applied automatically."
   ],
   "id": "391c131b6211c0c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# outliers = pd.read_csv(outliers_file, index_col=0, parse_dates=True)\n",
    "# outliers[\"smart_tether_Wind (degrees)\"] = outliers[\"smart_tether_Wind (m/s)\"]   # Remove WD values corresponding to outlying WS\n",
    "# outliers[\"flight_computer_Long\"] = outliers[\"flight_computer_Lat\"]              # Remove Long values corresponding to outlying Lat\n",
    "# outliers.to_csv(outliers_file, date_format=\"%Y-%m-%d %H:%M:%S\")                 # Save corresponding outliers into the csv file"
   ],
   "id": "d83fb745f9e67621",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.set_outliers_to_nan()\n",
    "#df.loc[\"2025-02-15 09:47:40\":\"2025-02-15 09:47:50\", 'smart_tether_Wind (m/s)']   # Print time range to control if values replaced by NaN"
   ],
   "id": "8f1c7aeaed6d3c27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set GPS data in case of missing FC files\n",
    "data_processor.fillna_if_all_missing({\"flight_computer_Lat\": 7039.724, \"flight_computer_Long\": 817.1591})"
   ],
   "id": "8af400f36c0f6288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.state()",
   "id": "44449018de5b023f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is possible to access and modify the data directly in cases where certain operations are not yet supported by the data processor.\n",
    "\n",
    "If an operation becomes part of the standard workflow, it is strongly encouraged to add it to the data processor instead."
   ],
   "id": "a64b53adf5b8fb04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#data_processor.df['flight_computer_pressure'] = data_processor.df['pops_pressure']",
   "id": "c093bec47e28d109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T17:49:54.847406Z",
     "start_time": "2025-12-12T17:49:54.575405Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "### Outlier removal double check\n",
    "Plot variables with possible removed outliers."
   ],
   "id": "164fbbe7231cd77c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_outliers_check()",
   "id": "802417f54908c02f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check position of balloon compared to the station based on GPS coordinates.\n",
    "\n",
    "Transformation of degrees-minutes coordinates (DM) into decimal degrees (DD) coordinates.\n",
    "Addition of 'latitude_dd' and 'longitude_dd' into df."
   ],
   "id": "ba3b5adb679f92db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.convert_gps_coordinates(lat_col='flight_computer_Lat', lon_col='flight_computer_Long',\n",
    "                                       lat_dir='S', lon_dir='W')\n",
    "data_processor.plot_gps_on_map(center_coords=(-70.6587, -8.2850), zoom_start=14)"
   ],
   "id": "9882c5f9b88163ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## T and RH averaging\n",
    "\n",
    "Averages flight computer temperature and humidity data from the two T/RH sensors.\n",
    "If > K NaNs for one of the sensors, takes only the other one into account, where K is a NaN threshold, which can be specified in `T_RH_averaging`.\n",
    "\n",
    "Plots T and RH as a function of pressure.\n",
    "Smart Tether is also plotted as an indication but not taken into account for the averaging.\n",
    "\n",
    "Adds 'Average_Temperature' and 'Average_RH' into df."
   ],
   "id": "e4d9699f7ae1639e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# if columns are not specified, takes the default flight computer columns\n",
    "data_processor.T_RH_averaging(columns_t=None, columns_rh=None, nan_threshold=400)\n",
    "data_processor.plot_T_RH(save_path=output_level1_dir / f\"Level1_{config.flight_basename}_T_RH_averaging.png\")"
   ],
   "id": "b1f8b864e52fdb21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**In case the standard T and RH averaging is not working, and the ST measurements need to be taken into account, update the cell above by:**\n",
    "\n",
    "Applying any required corrections to the smart tether T and RH measurements.\n",
    "```python\n",
    "data_processor.df['smart_tether_T (deg C)_corr'] = data_processor.df['smart_tether_T (deg C)'].ffill().bfill() - 0.2\n",
    "data_processor.df['smart_tether_%RH_corr'] = data_processor.df['smart_tether_%RH'].ffill().bfill() - 6.1\n",
    "```\n",
    "\n",
    "Specifying the columns to average in the function call, including smart tether T and RH measurements:\n",
    "```python\n",
    "data_processor.T_RH_averaging(\n",
    "    columns_t=['flight_computer_Out1_T', 'flight_computer_Out2_T', 'smart_tether_T (deg C)_corr'],\n",
    "    columns_rh=['flight_computer_Out1_H', 'flight_computer_Out2_H', 'smart_tether_%RH_corr'],\n",
    "    nan_threshold=400,\n",
    ")\n",
    "```"
   ],
   "id": "e06cd21361cf99fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Altitude calculation\n",
    "\n",
    "Adds 'DateTime', 'Pressure_ground', 'Temperature_ground' and 'Altitude' into df.\n",
    "\n",
    "**When FC started at the balloon height and not on the sledge:**\n",
    "specify the height of the sledge in meters in the `offset_to_add` parameter"
   ],
   "id": "70f8f75f77674e57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.altitude_calculation_barometric(offset_to_add=0)\n",
    "data_processor.df.head()"
   ],
   "id": "20fa08b464076bc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_altitude()",
   "id": "4603651c4988dcc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CO2 data processing",
   "id": "18562a0bfabbf537"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import co2\n",
    "\n",
    "data_processor.normalize(co2, min_threshold=200, max_threshold=500)\n",
    "data_processor.plot_raw_and_normalized_data(co2)"
   ],
   "id": "11859f80229f3998",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## STAP data processing",
   "id": "735a1a13d5374a52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import stap\n",
    "\n",
    "data_processor.normalize(stap)\n",
    "data_processor.plot_raw_and_normalized_data(stap)"
   ],
   "id": "57a91c80bf7cf14b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## POPS data processing\n",
    "### POPS total concentration calculation\n",
    "\n",
    "Calculate the total concentration and dN/dlogDP for each bin\n",
    "\n",
    "From Pohorsky et al. (2024) it appeared that particles with diameters between 142 and 186 (bins 0 to 2) are wrongly detected by the POPS as total particle concentration increases. This phenomenon can be explained by electronic noise from the detector, where fringes on the edge of the Gaussian signal are perceived as smaller particles by the software. It was therefore decided to only consider data for particles larger than 186 nm as the error induced by the first three bins is too high.\n",
    "\n",
    "*dN_pops = pops_bX / popsflow_mean = dN*  \n",
    "*pops_total_conc = sum of dN_pops*  \n",
    "*pops_bX_dlogDp = dN/dlogDp*  \n",
    "\n",
    "Adds 'pops_total_conc' and 'pops_bX_dlogDp' into df."
   ],
   "id": "49522a8bfdfd9790"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import pops\n",
    "\n",
    "data_processor.calculate_derived(pops)\n",
    "data_processor.plot_raw_and_normalized_data(pops)  # no normalized data yet -> only raw data will be plotted"
   ],
   "id": "4e28875d9e8852f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting POPS outliers to NaNs\n",
    "**Set `pops_has_outliers = True` if there are outliers in POPS measurements**\n",
    "\n",
    "If an observation being an outlier in one bin implies that observations in other bins are also outliers, set `use_coupled_columns=True`. In this case, marking an outlier in one column will automatically mark the corresponding values in the coupled columns as well.\n",
    "\n",
    "If you want to mark outliers in a single column only, set `use_coupled_columns=False`.\n",
    "\n",
    "See `pops.py` for the definition of the POPS instrument to check which columns are coupled:\n",
    "\n",
    "```python\n",
    "pops = POPS(\n",
    "    name=\"pops\",\n",
    "    ...\n",
    "    coupled_columns=[\n",
    "        ...\n",
    "    ]\n",
    ")\n",
    "```\n",
    "If the coupled columns need to be updated, modify `coupled_columns` and rerun the notebook for the changes to take effect.\n",
    "\n",
    "After the outliers are selected and the file is created, run\n",
    "`data_processor.set_outliers_to_nan()` (next cell) to update the data frame accordingly."
   ],
   "id": "1181ecc5087ba6aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set to True to choose outlier regions in POPS data\n",
    "pops_has_outliers = False\n",
    "\n",
    "if pops_has_outliers:\n",
    "    outliers_pops_file = output_level1_dir / f\"level1_{config.flight_basename}_outliers_pops.csv\"\n",
    "    data_processor.choose_outliers(y=\"Altitude\", outliers_file=outliers_pops_file, use_coupled_columns=True, instruments=[pops])"
   ],
   "id": "fad8fad6e605b840",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if pops_has_outliers:\n",
    "    data_processor.set_outliers_to_nan()"
   ],
   "id": "7ebfd71452ca4e1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: check 2025-02-12 07:57:25 + update coupled columns ? or change choose_outliers\n",
    "if False:\n",
    "    pd.Timestamp(\"2025-02-12 07:57:25\")\n",
    "    df.loc[\"2025-02-10 13:47:00\":\"2025-02-10 13:47:15\", 'pops_b3_dlogDp']"
   ],
   "id": "c24460055c7d42ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of POPS concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "\n",
    "       \n",
    "Adds 'pops_total_conc_stp' and 'pops_bX_dlogDp_stp' into df."
   ],
   "id": "bf2904a6147c11ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.normalize(pops)\n",
    "data_processor.plot_raw_and_normalized_data(pops)"
   ],
   "id": "fafc12d7c2d4217b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot POPS size distribution and total concentration  \n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "7837fee7fc9eda14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_distribution(pops)",
   "id": "7ff3c54ffaf52ee9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mSEMS data processing\n",
    "### mSEMS total concentration calculation\n",
    "\n",
    "*msems_inverted_Bin_ConcX = dN/dlogDp*  \n",
    "*msems_inverted_dN_Bin_ConcX = conc * dlogDp*  \n",
    "*msems_inverted_dN_totalconc = sum of msems_inverted_dN_Bin_ConcX*  \n",
    "\n",
    "Adds 'msems_inverted_dN_Bin_ConcX' and 'msems_inverted_dN_totalconc' into df."
   ],
   "id": "b9e1e3269d0bc7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import msems_inverted\n",
    "\n",
    "data_processor.calculate_derived(msems_inverted)\n",
    "data_processor.plot_raw_and_normalized_data(msems_inverted)  # no normalized data yet -> only raw data will be plotted"
   ],
   "id": "a6f815b54a8aa70a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting mSEMS outliers to NaNs\n",
    "**Set `msems_has_outliers = True` if there are outliers in msems measurements**\n",
    "\n",
    "If an observation being an outlier in one bin implies that observations in other bins are also outliers, set `use_coupled_columns=True`. In this case, marking an outlier in one column will automatically mark the corresponding values in the coupled columns as well.\n",
    "\n",
    "If you want to mark outliers in a single column only, set `use_coupled_columns=False`.\n",
    "\n",
    "See `msems.py` for the definition of the msems instrument to check which columns are coupled:\n",
    "\n",
    "```python\n",
    "msems = msems(\n",
    "    name=\"msems\",\n",
    "    ...\n",
    "    coupled_columns=[\n",
    "        ...\n",
    "    ]\n",
    ")\n",
    "```\n",
    "If the coupled columns need to be updated, modify `coupled_columns` and rerun the notebook for the changes to take effect.\n",
    "\n",
    "After the outliers are selected and the file is created, run\n",
    "`data_processor.set_outliers_to_nan()` (next cell) to update the data frame accordingly."
   ],
   "id": "f9c77627f6482f05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set to True to choose outlier regions in mSEMS data\n",
    "msems_has_outliers = False\n",
    "\n",
    "if msems_has_outliers:\n",
    "    outliers_msems_file = output_level1_dir / f\"level1_{config.flight_basename}_outliers_msems.csv\"\n",
    "    data_processor.choose_outliers(y=\"Altitude\", outliers_file=outliers_msems_file, use_coupled_columns=True, instruments=[msems_inverted])"
   ],
   "id": "e3e89d50c5dd97a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if msems_has_outliers:\n",
    "    data_processor.set_outliers_to_nan()"
   ],
   "id": "373dd5113a84eccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "import numpy as np\n",
    "\n",
    "if False:\n",
    "    # Define time range of \"bad\" mSEMS measurements\n",
    "    start_time = \"2025-01-27 17:55\"\n",
    "    end_time = \"2025-01-27 19:45\""
   ],
   "id": "e64fb4db6f8d2f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of mSEMS concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).\n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$\n",
    "\n",
    "Adds 'msems_inverted_Bin_ConcX_stp' and 'msems_inverted_dN_totalconc_stp' to df."
   ],
   "id": "50dce1a053ac2f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.normalize(msems_inverted)\n",
    "data_processor.plot_raw_and_normalized_data(msems_inverted)"
   ],
   "id": "7a95a6c662d0c5bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot mSEMS size distribution and total concentration\n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "bed1b0a0167c2e61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_distribution(msems_inverted, time_start=None, time_end=None)",
   "id": "4582af1fcc415bd3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## mCDA data processing\n",
    "### mCDA bin concentrations, total concentration and normalization per bin width\n",
    "\n",
    "For bins 1 to 256 :  \n",
    "*mcda_dataB X = raw counts*  \n",
    "*mcda_dataB X_dN = counts / (flow rate * sampling interval) = concentration*  \n",
    "*mcda_dN_totalconc = sum of mcda_dataBX_dN*  \n",
    "*mcda_dataB X_dN_dlogDp = dN/dlogDp = mcda_dataBX_dN / dlogDp*\n",
    "\n",
    "Adds 'mcda_dataB X_dN', 'mcda_dN_totalconc' and 'mcda_dataB X_dN_dlogDp' into df."
   ],
   "id": "b2b96d4402da6607"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import mcda\n",
    "\n",
    "data_processor.calculate_derived(mcda)\n",
    "data_processor.plot_raw_and_normalized_data(mcda)  # no normalized data yet -> only raw data will be plotted"
   ],
   "id": "ea68c77ee4de08b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting mCDA outliers to NaNs\n",
    "**Set `mcda_has_outliers = True` if there are outliers in mcda measurements**\n",
    "\n",
    "If an observation being an outlier in one bin implies that observations in other bins are also outliers, set `use_coupled_columns=True`. In this case, marking an outlier in one column will automatically mark the corresponding values in the coupled columns as well.\n",
    "\n",
    "If you want to mark outliers in a single column only, set `use_coupled_columns=False`.\n",
    "\n",
    "See `mcda.py` for the definition of the mcda instrument to check which columns are coupled:\n",
    "\n",
    "```python\n",
    "mcda = mcda(\n",
    "    name=\"mcda\",\n",
    "    ...\n",
    "    coupled_columns=[\n",
    "        ...\n",
    "    ]\n",
    ")\n",
    "```\n",
    "If the coupled columns need to be updated, modify `coupled_columns` and rerun the notebook for the changes to take effect.\n",
    "\n",
    "After the outliers are selected and the file is created, run\n",
    "`data_processor.set_outliers_to_nan()` (next cell) to update the data frame accordingly."
   ],
   "id": "f6e12ed81d78c8d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set to True to choose outlier regions in mCDA data\n",
    "mcda_has_outliers = False\n",
    "\n",
    "if mcda_has_outliers:\n",
    "    outliers_mcda_file = output_level1_dir / f\"level1_{config.flight_basename}_outliers_mcda.csv\"\n",
    "    data_processor.choose_outliers(y=\"Altitude\", outliers_file=outliers_mcda_file, use_coupled_columns=True, instruments=[mcda])"
   ],
   "id": "b544d9ebb4c0b139",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if mcda_has_outliers:\n",
    "    data_processor.set_outliers_to_nan()"
   ],
   "id": "49e1a91393f93c4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of mCDA concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "Adds 'mcda_dataB X_dN_dlogDp_stp' and 'mcda_dN_totalconc_stp' to df."
   ],
   "id": "ee8ca33d9da448e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.normalize(mcda)\n",
    "data_processor.plot_raw_and_normalized_data(mcda)"
   ],
   "id": "4773f5d86138bc51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Plot mCDA size distribution and total concentration\n",
    "\n",
    "STP normalized bin concentrations and total concentration"
   ],
   "id": "ee17f076cec0a021"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_distribution(mcda)",
   "id": "85f6ba6cf4dad069",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Vertical droplet size distribution**",
   "id": "58d4fe4183c58fad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.plot_vertical_distribution(mcda)",
   "id": "277445d9164a10b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CPC3007 data processing",
   "id": "fae277d0941e1d44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments import cpc\n",
    "\n",
    "data_processor.plot_raw_and_normalized_data(cpc)  # no normalized data yet -> only raw data will be plotted"
   ],
   "id": "d7d9ae076f30717",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting CPC3007 outliers to NaNs\n",
    "\n",
    "**Set `cpc_has_outliers = True` if there are outliers in cpc measurements**\n",
    "\n",
    "After the outliers in `cpc_totalconc_raw` are selected and the file is created, run\n",
    "`data_processor.set_outliers_to_nan()` (next cell) to update the data frame accordingly."
   ],
   "id": "cf13147ee742aab9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set to True to choose outlier regions in CPC3007 data\n",
    "cpc_has_outliers = False\n",
    "\n",
    "if cpc_has_outliers:\n",
    "    outliers_cpc_file = output_level1_dir / f\"level1_{config.flight_basename}_outliers_cpc.csv\"\n",
    "    data_processor.choose_outliers(y=\"Altitude\", outliers_file=outliers_cpc_file, use_coupled_columns=True, instruments=[cpc])"
   ],
   "id": "9601bc4d97fc8987",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if cpc_has_outliers:\n",
    "    data_processor.set_outliers_to_nan()"
   ],
   "id": "56d6f66b0eb79576",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalization of CPC3007 concentrations to standard temperature and pressure (STP)\n",
    "\n",
    "at 0°C (273.15 K) and 1 atm (1013.25 hPa).  \n",
    "\n",
    "$C_{\\text{STP}} = C_{\\text{measured}} \\times \\left( \\frac{P_{\\text{measured}}}{P_{\\text{STP}}} \\right) \\times \\left( \\frac{T_{\\text{STP}}}{T_{\\text{measured}}} \\right)$  \n",
    "\n",
    "\n",
    "       \n",
    "Adds 'CPC_total_N_stp' into df."
   ],
   "id": "57167f3600713803"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_processor.normalize(cpc)\n",
    "data_processor.plot_raw_and_normalized_data(cpc)"
   ],
   "id": "1646df5497f8e8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filter data check",
   "id": "416a12cc44303407"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# NO FILT DATA FROM FC --> READ IN THE FILT FILE AND PASTE IT INTO DF WITH CORRECT NAMES !!!!!",
   "id": "ebd1ab81838a3a06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: \"250127A3.TXT\"\n",
    "if False:\n",
    "    filt = pd.read_csv(DATA_FLIGHT_DIRPATH / \"250127A3.TXT\", skiprows=13, delimiter='\\t')  # or use sep=',' if it's CSV\n",
    "\n",
    "    date_str = filt['#YY/MM/DD'].str.strip()\n",
    "    time_str = filt['HR:MN:SC'].str.strip()\n",
    "    combined = date_str + ' ' + time_str\n",
    "    filt['datetime'] = pd.to_datetime(combined, format='%y/%m/%d %H:%M:%S')\n",
    "    filt = filt.set_index('datetime', drop=False)\n",
    "    filt.columns = 'filter_' + filt.columns.astype(str)\n",
    "\n",
    "    filt"
   ],
   "id": "627364299f721b5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    df = df.join(filt, how='left')\n",
    "    df"
   ],
   "id": "3103f1750708eb83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.processing.post.level1 import filter_data\n",
    "\n",
    "if False:\n",
    "    filter_data(df)"
   ],
   "id": "aca352bc77ed3ffc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**In case of broken filters, replace filter positions by 1.**",
   "id": "e12590dda4fce0d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    df['filter_cur_pos'] = 1\n",
    "    df['filter_pump_pw'] = 0"
   ],
   "id": "ada22e98cb21681a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    df.loc[df['filter_cur_pos'] == 0, 'filter_cur_pos'] = 1\n",
    "    df.loc[df['filter_cur_pos'] == 2, 'filter_cur_pos'] = 1\n",
    "    df.loc[df['filter_cur_pos'] == 4, 'filter_cur_pos'] = 1"
   ],
   "id": "d803ec3fd6b29b52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False:\n",
    "    broken_filter_start = pd.Timestamp(\"2025-02-11 15:44:14\")\n",
    "    broken_filter_end = pd.Timestamp(\"2025-02-11 16:11:39\")\n",
    "    df.loc[df['filter_cur_pos'] == 0, 'filter_cur_pos'] = 1\n",
    "\n",
    "    df.loc[(df.index >= broken_filter_start) & (df.index <= broken_filter_end), 'filter_cur_pos'] = 2.0\n",
    "    df.loc[(df.index >= broken_filter_start) & (df.index <= broken_filter_end), 'filter_pump_pw'] = 37.0\n",
    "    df['filter_cur_pos']"
   ],
   "id": "bac036fdd3aed299",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data quicklooks\n",
    "### Flight profile\n",
    "Variables plotted in the flight profile are normally defined in the output schema, so they remain consistent within a single campaign. See `helikite/classes/output_schemas.py`.\n",
    "\n",
    "By default, no variables are explicitly provided to the function, and the values from the output schema are used. If you want to change the variables being plotted, you can create a custom list of `FlightProfileVariable` objects and pass it via the `variables` argument.\n",
    "\n",
    "In the example below, we take a copy of the original list of variables for the campaign and replace the bounds defined for the 5th variable.\n",
    "\n",
    "```python\n",
    "import dataclasses\n",
    "\n",
    "custom_variables = data_processor.output_schema.flight_profile_variables.copy()\n",
    "custom_variables[4] = dataclasses.replace(custom_variables[4], x_divider=20, x_bounds=(0, 120))\n",
    "\n",
    "data_processor.plot_flight_profiles(config.flight_basename, save_path, variables=custom_variables)\n",
    "```\n",
    "In another example, we take a copy and replace the first variable with longitude in degrees.\n",
    "\n",
    "```python\n",
    "custom_variables[0] = FlightProfileVariable(\n",
    "    column_name=\"longitude_dd\",\n",
    "    plot_kwargs=dict(color=\"brown\", linewidth=3.0, marker='.', linestyle=\"none\"),\n",
    "    x_bounds=(-8.29, -8.26),\n",
    "    x_divider=0.01,\n",
    "    x_label=\"Longitude (dd)\",\n",
    ")\n",
    "\n",
    "data_processor.plot_flight_profiles(config.flight_basename, save_path, variables=custom_variables)\n",
    "```"
   ],
   "id": "908b74a73a42b75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_path = output_level1_dir / f'Level1_{config.flight_basename}_Flight_{config.flight}.png'\n",
    "\n",
    "data_processor.plot_flight_profiles(config.flight_basename, save_path, variables=None)"
   ],
   "id": "64d44be54b423a76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Size distributions",
   "id": "17cbb7db75b4d7e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_path = output_level1_dir / f'Level1_{config.flight_basename}_SizeDistr_Flight_{config.flight}.png'\n",
    "\n",
    "data_processor.plot_size_distr(config.flight_basename, save_path, time_start=None, time_end=None)"
   ],
   "id": "a3dcdf73ad798359",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Level 1\n",
    "**Save file containing all the columns (processed)**"
   ],
   "id": "3751cb06303aee8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_processor.export_data(filepath=output_level1_dir / f'level1_{config.flight_basename}.csv')",
   "id": "71e893230d784bb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Random code bits\n",
    "### Remove outliers from the Smart Tether WS and WD datapoints\n",
    "\n",
    "This is a **sliding-window median filter** used for **outlier detection and removal**.\n",
    "- Look at a window of neighboring values around each data point (10 neighboring values)\n",
    "- Compare the current point to the median of this window.\n",
    "- If the point is significantly different (>35% away from the median), it's treated as an outlier and **replaced with NaN**.\n",
    "\n",
    "Applied on WS, the corresponding WD datapoints are then also removed."
   ],
   "id": "f57bdf2e757b5789"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.instruments.smart_tether import wind_outlier_removal\n",
    "\n",
    "# set to True to apply the filter on WS and WD data\n",
    "apply_wind_filter = False\n",
    "\n",
    "if apply_wind_filter:\n",
    "    df_filtered = wind_outlier_removal(data_processor.df)"
   ],
   "id": "9ee6ce8d928af86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**IF THE FILTER APPLIES CORRECTLY** : save the filtered WS and WD data back into th original dataframe",
   "id": "6e4ee313eda72ea7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if apply_wind_filter:\n",
    "    # Save the filtered data back into th original dataframe\n",
    "    data_processor.df['smart_tether_Wind (m/s)'] = df_filtered['smart_tether_Wind (m/s)']\n",
    "    data_processor.df['smart_tether_Wind (degrees)'] = df_filtered['smart_tether_Wind (degrees)']\n",
    "    print(\"Filtered data saved to the original dataframe.\")"
   ],
   "id": "ad1596b342388a44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Metadata dictionary",
   "id": "9ab28c6ac98889a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Otherwise, to make a dictionary from the metadata:\n",
    "metadata_dict = metadata.model_dump()\n",
    "\n",
    "# Then use it as a normal Python dictionary\n",
    "metadata_dict['flight_date']"
   ],
   "id": "573f7670751157fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GPS coordinate check",
   "id": "15e049634df3ac00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# First y-axis for Longitude\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Longitude', color=color)\n",
    "ax1.plot(data_processor.df.index, data_processor.df['flight_computer_Long'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Second y-axis for Latitude\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Latitude', color=color)\n",
    "ax2.plot(data_processor.df.index, data_processor.df['flight_computer_Lat'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Longitude and Latitude over Time')\n",
    "plt.show()"
   ],
   "id": "6e950d42f67f9982",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from helikite.processing.post.outliers import convert_gps_coordinates\n",
    "\n",
    "lon_col, lat_col = 'flight_computer_Long', 'flight_computer_Lat'\n",
    "\n",
    "df_coord = data_processor.df[[lon_col, lat_col]].copy()\n",
    "df_coord = convert_gps_coordinates(df_coord, lat_col, lon_col, lat_dir=\"S\", lon_dir=\"W\")\n",
    "\n",
    "df_coord['latitude_dd']"
   ],
   "id": "5b5df98a69dcdfd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Export TAPIR data for Delphine",
   "id": "6833842d10ab6c8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set to True to export TAPIR data\n",
    "export_tapir_data = False\n",
    "\n",
    "if export_tapir_data:\n",
    "    # Create a new DataFrame with the same DateTime index as df\n",
    "    df_tapir = data_processor.df.loc[:, ['Altitude', 'Average_Temperature', 'Temperature_ground', 'mcda_dN_totalconc_stp'] +\n",
    "                                        [col for col in data_processor.df.columns if col.startswith('tapir_')]].copy()\n",
    "    df_tapir['Altitude'] = df_tapir['Altitude'].round(2)\n",
    "    df_tapir['Average_Temperature'] = df_tapir['Average_Temperature'].round(2)\n",
    "    df_tapir['mcda_dN_totalconc_stp'] = df_tapir['mcda_dN_totalconc_stp'].round(2)\n",
    "\n",
    "    df_tapir"
   ],
   "id": "5975b8371ac08bb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "if export_tapir_data:\n",
    "    # Example metadata as a dictionary (you can adjust this to your actual metadata object)\n",
    "    metadata_lines = {\n",
    "        'Flight date' : metadata.flight_date,\n",
    "        'Flight number' : metadata.flight,\n",
    "        'Takeoff time' : metadata.takeoff_time,\n",
    "        'Landing time' : metadata.landing_time,\n",
    "        'Average_Temperature (in °C)' : 'average T from two temperature sensors',\n",
    "        'Temperature_ground (in K)' : 'extrapolated ground temperature based on T at takeoff and landing',\n",
    "        'mcda_dN_totalconc_stp (cm-3)' : 'droplet total concentration',\n",
    "        'Note' : 'there are two \"peaks\" in the temperature profile, I am however not yet sure if they are significant or outliers'\n",
    "    }\n",
    "\n",
    "    # Construct the dynamic filename\n",
    "    filename = f\"{metadata.flight_date}_Flight{metadata.flight}_TAPIR.txt\"\n",
    "\n",
    "    # Define your output directory (use raw string if needed)\n",
    "    output_dir_tapir = output_level1_dir / \"tapir\"\n",
    "    output_dir_tapir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Combine the path and filename\n",
    "    output_path = os.path.join(output_dir_tapir, filename)\n",
    "\n",
    "    # Save the file\n",
    "    with open(output_path, 'w', newline='') as f:\n",
    "        for key, value in metadata_lines.items():\n",
    "            f.write(f\"# {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        df_tapir.to_csv(f, index=True)"
   ],
   "id": "77a3fcb435474ac6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
